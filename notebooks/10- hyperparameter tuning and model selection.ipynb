{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "885cdad4",
   "metadata": {},
   "source": [
    "https://machinelearning.wtf/terms/training-validation-test-datasets/  \n",
    "https://deepchecks.com/evaluating-model-performance-using-validation-dataset-splits-and-cross-validation-techniques/  \n",
    "https://stackoverflow.com/questions/52670012/convergencewarning-liblinear-failed-to-converge-increase-the-number-of-iterati  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8b3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e77c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)  # Set random seed for numpy\n",
    "\n",
    "import random\n",
    "random.seed(42)  # Set random seed for random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d588b6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>reason</th>\n",
       "      <th>description</th>\n",
       "      <th>zone</th>\n",
       "      <th>narrative_tfidf</th>\n",
       "      <th>narrative_embeddings</th>\n",
       "      <th>narrative_bert</th>\n",
       "      <th>narrative_tfidf_title</th>\n",
       "      <th>narrative_bert_title</th>\n",
       "      <th>...</th>\n",
       "      <th>embeddings_title</th>\n",
       "      <th>tfidf_keywords</th>\n",
       "      <th>embeddings_keywords</th>\n",
       "      <th>events_clean</th>\n",
       "      <th>results_final</th>\n",
       "      <th>events_tfidf</th>\n",
       "      <th>events_embeddings</th>\n",
       "      <th>orgs</th>\n",
       "      <th>locs</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-11 12:26:32</td>\n",
       "      <td>CTT - Encomenda entregue danificada e com etiq...</td>\n",
       "      <td>0</td>\n",
       "      <td>Bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>bom dia venho meio apresentar reclamação ctt e...</td>\n",
       "      <td>bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>Bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>ctt encomenda entregar danificar etiqueta envi...</td>\n",
       "      <td>ctt - encomenda entregue danificada e com etiq...</td>\n",
       "      <td>...</td>\n",
       "      <td>ctt - encomenda entregue danificada e com etiq...</td>\n",
       "      <td>apresentar reclamação caixa figura envio israe...</td>\n",
       "      <td>apresentar uma reclamação tinha caixa figura e...</td>\n",
       "      <td>venho apresentar enviei destinado feito proteg...</td>\n",
       "      <td>[('CTT', 'B-ORGANIZACAO'), ('Israel', 'B-LOCAL...</td>\n",
       "      <td>venho apresentar enviar destinar fazer protege...</td>\n",
       "      <td>venho apresentar enviei destinado feito proteg...</td>\n",
       "      <td>CTT, Aboboda</td>\n",
       "      <td>Israel</td>\n",
       "      <td>CTT, Aboboda, Israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-08-31 23:20:15</td>\n",
       "      <td>CTT - Carta com certificado rasgado!</td>\n",
       "      <td>1</td>\n",
       "      <td>- Boa Noite!\\r\\n\\r\\n- Venho por este meio recl...</td>\n",
       "      <td>Coimbra</td>\n",
       "      <td>bom noite venho meio reclamar data ás durante ...</td>\n",
       "      <td>- boa noite!\\r\\n\\r\\n- venho por este meio recl...</td>\n",
       "      <td>- Boa Noite! Venho por este meio reclamar que ...</td>\n",
       "      <td>ctt carta certificar rasgar bom noite venho me...</td>\n",
       "      <td>ctt - carta com certificado rasgado!  - Boa No...</td>\n",
       "      <td>...</td>\n",
       "      <td>ctt - carta com certificado rasgado !</td>\n",
       "      <td>lilia pimentel certificar profissional passage...</td>\n",
       "      <td>lilia pimentel certificado profissional passag...</td>\n",
       "      <td>venho reclamar deparei -me continha tem</td>\n",
       "      <td>[('Lilia', 'B-PESSOA'), ('Pimentel', 'I-PESSOA')]</td>\n",
       "      <td>venho reclamar deparar conter</td>\n",
       "      <td>venho reclamar deparei - me continha tem</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-01 19:08:32</td>\n",
       "      <td>CTT - Encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Boa tarde,\\r\\nNo dia 17 de Dezembro de 2020 en...</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>bom tarde dia dezembro enviar encomenda França...</td>\n",
       "      <td>boa tarde,\\r\\nno dia 00 de dezembro de 0000 en...</td>\n",
       "      <td>Boa tarde, No dia 17 de Dezembro de 2020 envie...</td>\n",
       "      <td>ctt encomenda registar nunca chegar destine o ...</td>\n",
       "      <td>ctt - encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>...</td>\n",
       "      <td>ctt - encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>frança correio registar frança correio encomen...</td>\n",
       "      <td>frança em correio registado frança em correio ...</td>\n",
       "      <td>enviei registado vejo chegou saiu chegou tem p...</td>\n",
       "      <td>[('França', 'B-LOCAL'), ('Roissy', 'B-ORGANIZA...</td>\n",
       "      <td>enviar registar vejo chegar sair chegar passar...</td>\n",
       "      <td>enviei registado vejo chegou saiu chegou tem p...</td>\n",
       "      <td>Roissy</td>\n",
       "      <td>França, ROISSY</td>\n",
       "      <td>Roissy, França, ROISSY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-04-19 09:04:34</td>\n",
       "      <td>CTT - Correio Verde</td>\n",
       "      <td>2</td>\n",
       "      <td>Bom dia,\\n\\nPretendia esclarecer uma situação ...</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>bom dia pretender esclarecer situação ocorrer ...</td>\n",
       "      <td>bom dia,\\n\\npretendia esclarecer uma situação ...</td>\n",
       "      <td>Bom dia, Pretendia esclarecer uma situação que...</td>\n",
       "      <td>ctt correio verde bom dia pretender esclarecer...</td>\n",
       "      <td>ctt - correio verde  Bom dia, Pretendia esclar...</td>\n",
       "      <td>...</td>\n",
       "      <td>ctt - correio verde</td>\n",
       "      <td>pretender esclarecer situação pretender esclar...</td>\n",
       "      <td>pretendia esclarecer uma situação pretendia es...</td>\n",
       "      <td>pretendia esclarecer ocorreu desloquei dado fe...</td>\n",
       "      <td>[('El', 'B-LOCAL'), ('Corte', 'I-LOCAL'), ('In...</td>\n",
       "      <td>pretender esclarecer ocorrer desloquei dar fec...</td>\n",
       "      <td>pretendia esclarecer ocorreu desloquei dado fe...</td>\n",
       "      <td>Correio</td>\n",
       "      <td>El Corte Inglés, Lisboa Verde</td>\n",
       "      <td>Correio, El Corte Inglés, Lisboa Verde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-04 10:20:41</td>\n",
       "      <td>CTT - Aviso de recepção da carta registada, pr...</td>\n",
       "      <td>2</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>Porto</td>\n",
       "      <td>venho meio solicitar vosso ajudar saber onde e...</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>ctt aviso recepção carta registar preciso urge...</td>\n",
       "      <td>ctt - aviso de recepção da carta registada, pr...</td>\n",
       "      <td>...</td>\n",
       "      <td>ctt - aviso de recepção da carta registada , p...</td>\n",
       "      <td>papal centro pois preciso urgentemente pois pr...</td>\n",
       "      <td>papais para o centro pois preciso dele urgente...</td>\n",
       "      <td>venho solicitar saber onde se encontra regista...</td>\n",
       "      <td>[]</td>\n",
       "      <td>venho solicitar saber onde encontrar registar ...</td>\n",
       "      <td>venho solicitar saber onde se encontra regista...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0  2021-10-11 12:26:32  CTT - Encomenda entregue danificada e com etiq...   \n",
       "1  2021-08-31 23:20:15               CTT - Carta com certificado rasgado!   \n",
       "2  2021-02-01 19:08:32  CTT - Encomenda registada que nunca chegou ao ...   \n",
       "3  2018-04-19 09:04:34                                CTT - Correio Verde   \n",
       "4  2019-07-04 10:20:41  CTT - Aviso de recepção da carta registada, pr...   \n",
       "\n",
       "   reason                                        description     zone  \\\n",
       "0       0  Bom dia venho por este meio apresentar uma rec...   Lisboa   \n",
       "1       1  - Boa Noite!\\r\\n\\r\\n- Venho por este meio recl...  Coimbra   \n",
       "2       2  Boa tarde,\\r\\nNo dia 17 de Dezembro de 2020 en...   Aveiro   \n",
       "3       2  Bom dia,\\n\\nPretendia esclarecer uma situação ...   Lisboa   \n",
       "4       2  venho por este meio solicitar a vossa ajuda pa...    Porto   \n",
       "\n",
       "                                     narrative_tfidf  \\\n",
       "0  bom dia venho meio apresentar reclamação ctt e...   \n",
       "1  bom noite venho meio reclamar data ás durante ...   \n",
       "2  bom tarde dia dezembro enviar encomenda França...   \n",
       "3  bom dia pretender esclarecer situação ocorrer ...   \n",
       "4  venho meio solicitar vosso ajudar saber onde e...   \n",
       "\n",
       "                                narrative_embeddings  \\\n",
       "0  bom dia venho por este meio apresentar uma rec...   \n",
       "1  - boa noite!\\r\\n\\r\\n- venho por este meio recl...   \n",
       "2  boa tarde,\\r\\nno dia 00 de dezembro de 0000 en...   \n",
       "3  bom dia,\\n\\npretendia esclarecer uma situação ...   \n",
       "4  venho por este meio solicitar a vossa ajuda pa...   \n",
       "\n",
       "                                      narrative_bert  \\\n",
       "0  Bom dia venho por este meio apresentar uma rec...   \n",
       "1  - Boa Noite! Venho por este meio reclamar que ...   \n",
       "2  Boa tarde, No dia 17 de Dezembro de 2020 envie...   \n",
       "3  Bom dia, Pretendia esclarecer uma situação que...   \n",
       "4  venho por este meio solicitar a vossa ajuda pa...   \n",
       "\n",
       "                               narrative_tfidf_title  \\\n",
       "0  ctt encomenda entregar danificar etiqueta envi...   \n",
       "1  ctt carta certificar rasgar bom noite venho me...   \n",
       "2  ctt encomenda registar nunca chegar destine o ...   \n",
       "3  ctt correio verde bom dia pretender esclarecer...   \n",
       "4  ctt aviso recepção carta registar preciso urge...   \n",
       "\n",
       "                                narrative_bert_title  ...  \\\n",
       "0  ctt - encomenda entregue danificada e com etiq...  ...   \n",
       "1  ctt - carta com certificado rasgado!  - Boa No...  ...   \n",
       "2  ctt - encomenda registada que nunca chegou ao ...  ...   \n",
       "3  ctt - correio verde  Bom dia, Pretendia esclar...  ...   \n",
       "4  ctt - aviso de recepção da carta registada, pr...  ...   \n",
       "\n",
       "                                    embeddings_title  \\\n",
       "0  ctt - encomenda entregue danificada e com etiq...   \n",
       "1              ctt - carta com certificado rasgado !   \n",
       "2  ctt - encomenda registada que nunca chegou ao ...   \n",
       "3                                ctt - correio verde   \n",
       "4  ctt - aviso de recepção da carta registada , p...   \n",
       "\n",
       "                                      tfidf_keywords  \\\n",
       "0  apresentar reclamação caixa figura envio israe...   \n",
       "1  lilia pimentel certificar profissional passage...   \n",
       "2  frança correio registar frança correio encomen...   \n",
       "3  pretender esclarecer situação pretender esclar...   \n",
       "4  papal centro pois preciso urgentemente pois pr...   \n",
       "\n",
       "                                 embeddings_keywords  \\\n",
       "0  apresentar uma reclamação tinha caixa figura e...   \n",
       "1  lilia pimentel certificado profissional passag...   \n",
       "2  frança em correio registado frança em correio ...   \n",
       "3  pretendia esclarecer uma situação pretendia es...   \n",
       "4  papais para o centro pois preciso dele urgente...   \n",
       "\n",
       "                                        events_clean  \\\n",
       "0  venho apresentar enviei destinado feito proteg...   \n",
       "1            venho reclamar deparei -me continha tem   \n",
       "2  enviei registado vejo chegou saiu chegou tem p...   \n",
       "3  pretendia esclarecer ocorreu desloquei dado fe...   \n",
       "4  venho solicitar saber onde se encontra regista...   \n",
       "\n",
       "                                       results_final  \\\n",
       "0  [('CTT', 'B-ORGANIZACAO'), ('Israel', 'B-LOCAL...   \n",
       "1  [('Lilia', 'B-PESSOA'), ('Pimentel', 'I-PESSOA')]   \n",
       "2  [('França', 'B-LOCAL'), ('Roissy', 'B-ORGANIZA...   \n",
       "3  [('El', 'B-LOCAL'), ('Corte', 'I-LOCAL'), ('In...   \n",
       "4                                                 []   \n",
       "\n",
       "                                        events_tfidf  \\\n",
       "0  venho apresentar enviar destinar fazer protege...   \n",
       "1                      venho reclamar deparar conter   \n",
       "2  enviar registar vejo chegar sair chegar passar...   \n",
       "3  pretender esclarecer ocorrer desloquei dar fec...   \n",
       "4  venho solicitar saber onde encontrar registar ...   \n",
       "\n",
       "                                   events_embeddings          orgs  \\\n",
       "0  venho apresentar enviei destinado feito proteg...  CTT, Aboboda   \n",
       "1           venho reclamar deparei - me continha tem           NaN   \n",
       "2  enviei registado vejo chegou saiu chegou tem p...        Roissy   \n",
       "3  pretendia esclarecer ocorreu desloquei dado fe...       Correio   \n",
       "4  venho solicitar saber onde se encontra regista...           NaN   \n",
       "\n",
       "                            locs                                entities  \n",
       "0                         Israel                    CTT, Aboboda, Israel  \n",
       "1                            NaN                                     NaN  \n",
       "2                 França, ROISSY                  Roissy, França, ROISSY  \n",
       "3  El Corte Inglés, Lisboa Verde  Correio, El Corte Inglés, Lisboa Verde  \n",
       "4                            NaN                                     NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\data\\\\data_processed_selected.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a1b1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entities(row):\n",
    "    if pd.isna(row)==False:\n",
    "        entities = row.lower()  # Convert to lowercase\n",
    "        entities = entities.replace(',', '')  # Remove commas\n",
    "        entities = ' '.join(set(entities.split()))  # Convert to set to get unique values, then join back as a string\n",
    "        return entities\n",
    "df['entities'] = df['entities'].apply(preprocess_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "156eecec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          ctt aboboda israel\n",
       "1                                        None\n",
       "2                               frança roissy\n",
       "3        correio lisboa corte verde el inglés\n",
       "4                                        None\n",
       "                         ...                 \n",
       "22425                ctt portugal unido reino\n",
       "22426                                    None\n",
       "22427                              aliexpress\n",
       "22428                                  lisboa\n",
       "22429                                    None\n",
       "Name: entities, Length: 22430, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entities']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ab9e3",
   "metadata": {},
   "source": [
    "## TF-IDF  \n",
    "best results:  \n",
    "narrative_tfidf, tfidf_title\t                Linear SVC\t0.666766\t0.545398\t0.467301\t0.479607  \n",
    "narrative_tfidf, tfidf_title, tfidf_keywords\tXGBoost  \t0.664090\t0.559104\t0.456817\t0.467326  \n",
    "concatenate evrything in one string and use combinations where at least one feature exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87313292",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df[['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87dc2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15701, 5)\n",
      "y_train shape: (15701,)\n",
      "X_val shape: (3364, 5)\n",
      "y_val shape: (3364,)\n",
      "X_test shape: (3365, 5)\n",
      "y_test shape: (3365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b39f4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.concat([X_train, X_val], axis=0, ignore_index=True)\n",
    "y_train_val = pd.concat([y_train, y_val], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bd564",
   "metadata": {},
   "source": [
    "* **LinearSVC**   \n",
    "\n",
    "multiple param_grids because some hyperparameters are not compatible:\n",
    "* l1 only works with squared_hinge and dual=False\n",
    "* l2 works with both hinge and squared_hinge, but:\n",
    "* l2 and hinge only work with dual=True\n",
    "* l2 and squared_hinge work with both dual=True or dual=False\n",
    "* dual = True if number of features > number of examples \n",
    "* C>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cccfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "feature_set=['narrative_tfidf', 'tfidf_title', 'tfidf_keywords']\n",
    "X_train_val_combined = X_train_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "X_test_combined = X_test[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "# Transform the features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "X_train_val_combined_transformed = vectorizer.fit_transform(X_train_val_combined)\n",
    "X_test_combined_transformed = vectorizer.transform(X_test_combined)\n",
    "\n",
    "# Define the parameter grid\n",
    "# Define multiple hyperparameter grids\n",
    "param_grid_1 = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'penalty': ['l1'],\n",
    "    'dual': [False],\n",
    "    'max_iter': [3000, 4000, 5000, 6000, 7000]\n",
    "}\n",
    "\n",
    "param_grid_2 = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "    'loss': ['hinge'],\n",
    "    'penalty': ['l2'],\n",
    "    'dual': [True],\n",
    "    'max_iter': [3000, 4000, 5000, 6000, 7000]\n",
    "}\n",
    "\n",
    "param_grid_3 = {\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],\n",
    "    'loss': ['squared_hinge'],\n",
    "    'penalty': ['l2'],\n",
    "    'dual': [True, False],\n",
    "    'max_iter': [3000, 4000, 5000, 6000, 7000]\n",
    "}\n",
    "\n",
    "# Combine the hyperparameter grids into a list\n",
    "param_grids = [param_grid_1, param_grid_2, param_grid_3]\n",
    "# 'max_iter': [3000, 4000, 5000, 6000, 30000]\n",
    "# 'max_iter': [10000, 15000, 20000, 25000, 30000]\n",
    "\n",
    "# Create the LinearSVC model\n",
    "svc = LinearSVC()\n",
    "\n",
    "# Create the stratified 6-fold cross-validation splitter for validation data\n",
    "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "# Set up grid search with the estimator and parameter grid\n",
    "grid_search = GridSearchCV(svc, param_grids, scoring='f1_macro', cv=cv)\n",
    "\n",
    "# Capture warnings during grid search\n",
    "with warnings.catch_warnings(record=True) as caught_warnings:\n",
    "    # Run grid search\n",
    "    grid_search.fit(X_train_val_combined_transformed, y_train_val)\n",
    "\n",
    "# Check captured warnings and print corresponding hyperparameter combinations\n",
    "for warning in caught_warnings:\n",
    "    if 'ConvergenceWarning' in str(warning.message):\n",
    "        print(f\"Warning: {warning.message}\")\n",
    "        print(\"Parameters:\", warning.category.parameters)\n",
    "\n",
    "# Perform GridSearch with cross-validation on the validation set\n",
    "print(\"best mean cross-validation f1-score: {:.3f}\".format(grid_search.best_score_))\n",
    "\n",
    "# or perform RandomizedSearchCV with cross-validation on the validation set\n",
    "# random_search = RandomizedSearchCV(svc, param_distributions=param_grids, n_iter=20, scoring='f1_macro', cv=cv, random_state=42)\n",
    "# random_search.fit(X_train_val_combined_transformed, y_train_val)\n",
    "# print(\"best mean cross-validation f1-score: {:.3f}\".format(random_search.best_score_))\n",
    "\n",
    "\n",
    "# Get the best LinearSVC model with tuned hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a41ead4",
   "metadata": {},
   "source": [
    "The cv_scores variable will store an array containing the F1 macro scores obtained for each fold during cross-validation. The length of this array will be equal to the number of folds specified in the cv parameter.  \n",
    "The cross_val_score function performs cross-validation using the same data splits defined by the cv parameter, regardless of the scoring metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa0d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation with StratifiedKFold\n",
    "f1_scores = cross_val_score(best_model, X_train_val_combined_transformed, y_train_val, cv=cv, scoring='f1_macro')\n",
    "\n",
    "print(\"Individual fold F1-scores:\", f1_scores)\n",
    "# check if the output is the same as before\n",
    "print(\"Mean cross-validation F1-score:\", f1_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6792de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check other metrics\n",
    "acc_scores = cross_val_score(best_model, X_train_val_combined_transformed, y_train_val, cv=cv, scoring='accuracy')\n",
    "rec_scores = cross_val_score(best_model, X_train_val_combined_transformed, y_train_val, cv=cv, scoring='recall_macro')\n",
    "prec_scores = cross_val_score(best_model, X_train_val_combined_transformed, y_train_val, cv=cv, scoring='precision_macro')\n",
    "\n",
    "print(\"Individual Precision:\", prec_scores)\n",
    "print(\"Mean cross-validation Precision:\", prec_scores.mean())\n",
    "print(\"Individual Accuracy:\", acc_scores)\n",
    "# or np.mean\n",
    "print(\"Mean cross-validation Accuracy:\", acc_scores.mean())\n",
    "print(\"Individual Recall:\", rec_scores)\n",
    "print(\"Mean cross-validation Recall:\", rec_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835593bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on full training set using the best hyperparameters\n",
    "best_model.fit(X_train_val_combined_transformed, y_train_val)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred_test = best_model.predict(X_test_combined_transformed)\n",
    "print('test classification report')\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Print the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "confusion_mat = confusion_matrix(y_true=y_test, y_pred=y_pred_test, labels=[0,1,2,3])\n",
    "ax.matshow(confusion_mat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confusion_mat.shape[0]):\n",
    "    for j in range(confusion_mat.shape[1]):\n",
    "        ax.text(x=j, y=i,s=confusion_mat[i, j], va='center', ha='center', size='xx-large')\n",
    "plt.xlabel('Predictions', fontsize=10)\n",
    "plt.ylabel('Actuals', fontsize=10)\n",
    "plt.title('Confusion Matrix', fontsize=10)\n",
    "plt.show()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c655b9",
   "metadata": {},
   "source": [
    "Learning curves are graphical representations that show how the performance of a machine learning model evolves as the amount of training data increases. They are useful for assessing whether a model is suffering from high bias (underfitting) or high variance (overfitting). Learning curves plot the training and validation performance (e.g., accuracy or error) as a function of the number of training examples used.\n",
    "\n",
    "In the resulting learning curve plot, you should look for the following patterns:\n",
    "\n",
    "1. High bias (Underfitting): If both the training and validation scores are relatively low and close together, it suggests the model has high bias and is not complex enough to capture the underlying patterns in the data. In this case, collecting more data might not significantly improve the model's performance.\n",
    "\n",
    "2. High variance (Overfitting): If there is a substantial gap between the training and validation scores, and the training score is much higher, it indicates the model has high variance and is overfitting the training data. Collecting more data may help in reducing overfitting.\n",
    "\n",
    "3. Good fit: If the training and validation scores converge at a relatively high value, it suggests that the model is well-fitted and generalizes well to unseen data. Collecting more data may not be necessary in this scenario.  \n",
    "\n",
    "\n",
    "The cv parameter in the learning_curve function specifies the cross-validation splitting strategy to use when calculating the learning curves. I used stratified 6fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfadef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Learning Curves\n",
    "# Create StratifiedKFold cross-validator with 6 folds\n",
    "cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(best_model, X_train_val, y_train_val, cv=stratified_cv, \n",
    "                                                       scoring='f1_macro', train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       random_state=42)\n",
    "\n",
    "# Calculate mean and standard deviation of training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(val_scores, axis=1)\n",
    "valid_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color='blue')\n",
    "plt.plot(train_sizes, valid_scores_mean, label='Cross-validation score', color='red')\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std,\n",
    "                 valid_scores_mean + valid_scores_std, alpha=0.2, color='red')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('F1 Macro Score')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(best_model, X_train_val, y_train_val, cv=stratified_cv, \n",
    "                                                       scoring='accuracy', train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "                                                       random_state=42)\n",
    "\n",
    "# Calculate mean and standard deviation of training and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(val_scores, axis=1)\n",
    "valid_scores_std = np.std(val_scores, axis=1)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training score', color='blue')\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2, color='blue')\n",
    "plt.plot(train_sizes, valid_scores_mean, label='Cross-validation score', color='red')\n",
    "plt.fill_between(train_sizes, valid_scores_mean - valid_scores_std,\n",
    "                 valid_scores_mean + valid_scores_std, alpha=0.2, color='red')\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curves')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d216b1a",
   "metadata": {},
   "source": [
    "* **XGBoost**  \n",
    "Performing hyperparameter tuning with grid search on XGBoost is generally more computationally intensive than doing hyperparameter tuning on LinearSVC, because of Model complexity, Number of hyperparameters, Cross-validation takes longer, XGBoost is an ensemble method.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set=['narrative_tfidf', 'tfidf_title', 'tfidf_keywords']\n",
    "X_train_combined = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "X_val_combined = X_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "X_test_combined = X_test[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "# Transform the features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "X_val_combined_transformed = vectorizer.transform(X_val_combined)\n",
    "X_test_combined_transformed = vectorizer.transform(X_test_combined)\n",
    "\n",
    "# Fit the base model\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='f1', cv=5)\n",
    "\n",
    "# Perform grid search on training data\n",
    "grid_search.fit(X_train_combined_transformed, y_train)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "print('Best model ', best_model)\n",
    "print('Best params ', best_params)\n",
    "print('Best score ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the validation set\n",
    "best_model = LinearSVC(**best_params)\n",
    "y_val_pred = best_model.predict(X_val_combined_transformed)\n",
    "\n",
    "# Calculate performance metrics\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred, average='macro')\n",
    "recall = recall_score(y_val, y_val_pred, average='macro')\n",
    "f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-score: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa987de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on test set\n",
    "y_pred_test = best_model.predict(X_test_combined_transformed)\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "precision = precision_score(y_test, y_pred_test, average='macro')\n",
    "recall = recall_score(y_test, y_pred_test, average='macro')\n",
    "f1 = f1_score(y_test, y_pred_test, average='macro')\n",
    "print('Test Accuracy: ', accuracy)\n",
    "print('Test Precision: ', precision)\n",
    "print('Test Recall: ', recall)\n",
    "print('Test F1-score: ', f1)\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ce548",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b457494",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df[['narrative_embeddings', 'embeddings_title', 'embeddings_keywords', 'events_embeddings', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb352c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v= KeyedVectors.load_word2vec_format('D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\embeddings\\\\skip_s600_word2vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb07f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove= KeyedVectors.load_word2vec_format('D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\embeddings\\\\glove_s600.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5e269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
