{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4788adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk import word_tokenize\n",
    "from sklearn.preprocessing import MinMaxScaler #fixed import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876e4d1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>reason</th>\n",
       "      <th>description</th>\n",
       "      <th>zone</th>\n",
       "      <th>narrative_tfidf</th>\n",
       "      <th>narrative_embeddings</th>\n",
       "      <th>narrative_bert</th>\n",
       "      <th>narrative_tfidf_title</th>\n",
       "      <th>narrative_bert_title</th>\n",
       "      <th>narrative_embeddings_title</th>\n",
       "      <th>tfidf_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-11 12:26:32</td>\n",
       "      <td>CTT - Encomenda entregue danificada e com etiq...</td>\n",
       "      <td>Mau Serviço Prestado</td>\n",
       "      <td>Bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>bom dia venho meio apresentar reclamação ctt e...</td>\n",
       "      <td>bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>Bom dia venho por este meio apresentar uma rec...</td>\n",
       "      <td>ctt encomenda entregar danificar etiqueta envi...</td>\n",
       "      <td>ctt - encomenda entregue danificada e com etiq...</td>\n",
       "      <td>ctt - encomenda entregue danificada e com etiq...</td>\n",
       "      <td>ctt encomenda entregar danificar etiqueta envi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-31 23:20:15</td>\n",
       "      <td>CTT - Carta com certificado rasgado!</td>\n",
       "      <td>Condições de entrega</td>\n",
       "      <td>- Boa Noite!\\r\\n\\r\\n- Venho por este meio recl...</td>\n",
       "      <td>Coimbra</td>\n",
       "      <td>bom noite venho meio reclamar data ás durante ...</td>\n",
       "      <td>- boa noite!\\r\\n\\r\\n- venho por este meio recl...</td>\n",
       "      <td>- Boa Noite! - Venho por este meio reclamar qu...</td>\n",
       "      <td>ctt carta certificar rasgar bom noite venho me...</td>\n",
       "      <td>ctt - carta com certificado rasgado!  - Boa No...</td>\n",
       "      <td>ctt - carta com certificado rasgado ! - boa no...</td>\n",
       "      <td>ctt carta certificar rasgar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-02-01 19:08:32</td>\n",
       "      <td>CTT - Encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>Atraso de entrega</td>\n",
       "      <td>Boa tarde,\\r\\nNo dia 17 de Dezembro de 2020 en...</td>\n",
       "      <td>Aveiro</td>\n",
       "      <td>bom tarde dia dezembro enviar encomenda França...</td>\n",
       "      <td>boa tarde,\\r\\nno dia 00 de dezembro de 0000 en...</td>\n",
       "      <td>Boa tarde, No dia 17 de Dezembro de 2020 envie...</td>\n",
       "      <td>ctt encomenda registar nunca chegar destine o ...</td>\n",
       "      <td>ctt - encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>ctt - encomenda registada que nunca chegou ao ...</td>\n",
       "      <td>ctt encomenda registar nunca chegar destine o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-19 09:04:34</td>\n",
       "      <td>CTT - Correio Verde</td>\n",
       "      <td>Atraso de entrega</td>\n",
       "      <td>Bom dia,\\n\\nPretendia esclarecer uma situação ...</td>\n",
       "      <td>Lisboa</td>\n",
       "      <td>bom dia pretender esclarecer situação ocorrer ...</td>\n",
       "      <td>bom dia,\\n\\npretendia esclarecer uma situação ...</td>\n",
       "      <td>Bom dia, Pretendia esclarecer uma situação que...</td>\n",
       "      <td>ctt correio verde bom dia pretender esclarecer...</td>\n",
       "      <td>ctt - correio verde  Bom dia, Pretendia esclar...</td>\n",
       "      <td>ctt - correio verde bom dia,\\n\\npretendia escl...</td>\n",
       "      <td>ctt correio verde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-07-04 10:20:41</td>\n",
       "      <td>CTT - Aviso de recepção da carta registada, pr...</td>\n",
       "      <td>Atraso de entrega</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>Porto</td>\n",
       "      <td>venho meio solicitar vosso ajudar saber onde e...</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>venho por este meio solicitar a vossa ajuda pa...</td>\n",
       "      <td>ctt aviso recepção carta registar preciso urge...</td>\n",
       "      <td>ctt - aviso de recepção da carta registada, pr...</td>\n",
       "      <td>ctt - aviso de recepção da carta registada , p...</td>\n",
       "      <td>ctt aviso recepção carta registar preciso urge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  \\\n",
       "0           0  2021-10-11 12:26:32   \n",
       "1           1  2021-08-31 23:20:15   \n",
       "2           2  2021-02-01 19:08:32   \n",
       "3           3  2018-04-19 09:04:34   \n",
       "4           4  2019-07-04 10:20:41   \n",
       "\n",
       "                                               title                reason  \\\n",
       "0  CTT - Encomenda entregue danificada e com etiq...  Mau Serviço Prestado   \n",
       "1               CTT - Carta com certificado rasgado!  Condições de entrega   \n",
       "2  CTT - Encomenda registada que nunca chegou ao ...     Atraso de entrega   \n",
       "3                                CTT - Correio Verde     Atraso de entrega   \n",
       "4  CTT - Aviso de recepção da carta registada, pr...     Atraso de entrega   \n",
       "\n",
       "                                         description     zone  \\\n",
       "0  Bom dia venho por este meio apresentar uma rec...   Lisboa   \n",
       "1  - Boa Noite!\\r\\n\\r\\n- Venho por este meio recl...  Coimbra   \n",
       "2  Boa tarde,\\r\\nNo dia 17 de Dezembro de 2020 en...   Aveiro   \n",
       "3  Bom dia,\\n\\nPretendia esclarecer uma situação ...   Lisboa   \n",
       "4  venho por este meio solicitar a vossa ajuda pa...    Porto   \n",
       "\n",
       "                                     narrative_tfidf  \\\n",
       "0  bom dia venho meio apresentar reclamação ctt e...   \n",
       "1  bom noite venho meio reclamar data ás durante ...   \n",
       "2  bom tarde dia dezembro enviar encomenda França...   \n",
       "3  bom dia pretender esclarecer situação ocorrer ...   \n",
       "4  venho meio solicitar vosso ajudar saber onde e...   \n",
       "\n",
       "                                narrative_embeddings  \\\n",
       "0  bom dia venho por este meio apresentar uma rec...   \n",
       "1  - boa noite!\\r\\n\\r\\n- venho por este meio recl...   \n",
       "2  boa tarde,\\r\\nno dia 00 de dezembro de 0000 en...   \n",
       "3  bom dia,\\n\\npretendia esclarecer uma situação ...   \n",
       "4  venho por este meio solicitar a vossa ajuda pa...   \n",
       "\n",
       "                                      narrative_bert  \\\n",
       "0  Bom dia venho por este meio apresentar uma rec...   \n",
       "1  - Boa Noite! - Venho por este meio reclamar qu...   \n",
       "2  Boa tarde, No dia 17 de Dezembro de 2020 envie...   \n",
       "3  Bom dia, Pretendia esclarecer uma situação que...   \n",
       "4  venho por este meio solicitar a vossa ajuda pa...   \n",
       "\n",
       "                               narrative_tfidf_title  \\\n",
       "0  ctt encomenda entregar danificar etiqueta envi...   \n",
       "1  ctt carta certificar rasgar bom noite venho me...   \n",
       "2  ctt encomenda registar nunca chegar destine o ...   \n",
       "3  ctt correio verde bom dia pretender esclarecer...   \n",
       "4  ctt aviso recepção carta registar preciso urge...   \n",
       "\n",
       "                                narrative_bert_title  \\\n",
       "0  ctt - encomenda entregue danificada e com etiq...   \n",
       "1  ctt - carta com certificado rasgado!  - Boa No...   \n",
       "2  ctt - encomenda registada que nunca chegou ao ...   \n",
       "3  ctt - correio verde  Bom dia, Pretendia esclar...   \n",
       "4  ctt - aviso de recepção da carta registada, pr...   \n",
       "\n",
       "                          narrative_embeddings_title  \\\n",
       "0  ctt - encomenda entregue danificada e com etiq...   \n",
       "1  ctt - carta com certificado rasgado ! - boa no...   \n",
       "2  ctt - encomenda registada que nunca chegou ao ...   \n",
       "3  ctt - correio verde bom dia,\\n\\npretendia escl...   \n",
       "4  ctt - aviso de recepção da carta registada , p...   \n",
       "\n",
       "                                         tfidf_title  \n",
       "0  ctt encomenda entregar danificar etiqueta envi...  \n",
       "1                        ctt carta certificar rasgar  \n",
       "2      ctt encomenda registar nunca chegar destine o  \n",
       "3                                  ctt correio verde  \n",
       "4  ctt aviso recepção carta registar preciso urge...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\data\\\\data_processed_selected.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754d7e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert reason to numbers\n",
    "reason_dict ={'Mau Serviço Prestado': 0, 'Condições de entrega': 1, 'Atraso de entrega': 2, \n",
    "               'Enganos': 3}\n",
    "df['reason'].replace(reason_dict, inplace=True)\n",
    "df['reason'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3e226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df.loc[:, df.columns != 'reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abe9bfd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15701, 12)\n",
      "y_train shape: (15701,)\n",
      "X_val shape: (3364, 12)\n",
      "y_val shape: (3364,)\n",
      "X_test shape: (3365, 12)\n",
      "y_test shape: (3365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ed6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train['narrative_tfidf']\n",
    "X_val=X_val['narrative_tfidf']\n",
    "X_test=X_test['narrative_tfidf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bca6940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9426     bom tarde pensar chegar ponto escrever reclama...\n",
       "15992    aguardar encomenda Brasil recebi aviso mesmo h...\n",
       "944      bom tarde fiz u encomenda enviar dia Janeiro s...\n",
       "3570     constante carteiro entregar carta morada compl...\n",
       "20225    fiz encomenda alemanho em este encomenda haver...\n",
       "                               ...                        \n",
       "2002     bom tarde fiz envio união europeu primeiro vez...\n",
       "6680     procedir envio encomenda enviar correio regist...\n",
       "8802     venho meio mostrar descontentamento serviço en...\n",
       "6405     venho meio reclamar serviço expresso ctt fiz u...\n",
       "18535    algum motivo todo correspondência enviar trás ...\n",
       "Name: narrative_tfidf, Length: 15701, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14fe4e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9784     enviar encomenda correio registar Portugal hol...\n",
       "12557    comprar cd Internet novembro chegar ctt dia de...\n",
       "15687    após ter receber informativo encomenda haver c...\n",
       "13491    encomenda origem holando cujo paradeiro em est...\n",
       "17418    mercadoria chegada mês aguardar resolução núme...\n",
       "                               ...                        \n",
       "628      passar dia março efectuei entregar carta vosso...\n",
       "18173    bom pedir vosso ajudar seguinte esperar encome...\n",
       "13078    enviar Portugal paço Ferreira encomenda dia de...\n",
       "19406    venho de este meio fazer reclamação facto rece...\n",
       "1059     fiz encomenda aliexpress ainda aguardar sempre...\n",
       "Name: narrative_tfidf, Length: 3364, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc453347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750     fiz encomenda shein chegar Portugal ctt morada...\n",
       "4563     desde venho mostrar desagrar ctt vez encomenda...\n",
       "4640     venho meio manifestar descontentamento ctt int...\n",
       "12810    venho meio reclamar data recebi subsidio paren...\n",
       "10038    estar esperar encomenda compra efectuar online...\n",
       "                               ...                        \n",
       "10820    imenso encomenda internacional chegar Lisboa s...\n",
       "4812     dia mês outubro chegar Portugal encomenda vind...\n",
       "4229     venho meio reclamar relativamente processo reg...\n",
       "893      bom dia gostar fazer reclamação relação encome...\n",
       "7312     bom tarde seguinte hoje dia março contactei wo...\n",
       "Name: narrative_tfidf, Length: 3365, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2930f29d",
   "metadata": {},
   "source": [
    "# No scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9c2174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training (clf,X_train, X_val, y_train, y_val,ngram, maxf):\n",
    "    ngram=ngram #tuplo\n",
    "    maxf=maxf\n",
    "    \n",
    "    # Perform tf-idf vectorization on the training set\n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram, max_features=maxf)\n",
    "    X_train_tf = tfidf.fit_transform(X_train)\n",
    "    \n",
    "    # Use the same vectorizer to transform the validation set\n",
    "    X_val_tf = tfidf.transform(X_val)\n",
    "        \n",
    "    #Train classifier on the training set\n",
    "    clf.fit(X_train_tf, y_train)\n",
    "    \n",
    "    # Predict the labels on the validation set\n",
    "    y_val_pred = clf.predict(X_val_tf)\n",
    "    # Predict the labels on the train set\n",
    "    y_train_pred = clf.predict(X_train_tf) \n",
    "\n",
    "    # Compute the accuracy of the model on the training set\n",
    "    acc_val = accuracy_score(y_train, y_train_pred)\n",
    "    print(\"Training accuracy:\", acc_val)\n",
    "    \n",
    "    return classification_report(y_val, y_val_pred), confusion_matrix(y_val, y_val_pred, labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c72c4156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7036494490796764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.55      1195\n",
      "           1       0.24      0.11      0.15       333\n",
      "           2       0.67      0.76      0.71      1609\n",
      "           3       0.25      0.10      0.14       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.42      0.38      0.39      3364\n",
      "weighted avg       0.55      0.58      0.56      3364\n",
      "\n",
      "[[ 687   61  411   36]\n",
      " [ 173   35  107   18]\n",
      " [ 350   29 1215   15]\n",
      " [  99   22   83   23]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.49      0.48      1195\n",
      "           1       0.14      0.14      0.14       333\n",
      "           2       0.64      0.64      0.64      1609\n",
      "           3       0.15      0.14      0.15       227\n",
      "\n",
      "    accuracy                           0.50      3364\n",
      "   macro avg       0.35      0.35      0.35      3364\n",
      "weighted avg       0.50      0.50      0.50      3364\n",
      "\n",
      "[[ 581  144  397   73]\n",
      " [ 161   46   94   32]\n",
      " [ 410   95 1032   72]\n",
      " [  83   34   78   32]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1195\n",
      "           1       0.64      0.03      0.05       333\n",
      "           2       0.68      0.89      0.77      1609\n",
      "           3       0.75      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.67      0.39      0.37      3364\n",
      "weighted avg       0.65      0.65      0.59      3364\n",
      "\n",
      "[[ 751    0  444    0]\n",
      " [ 188    9  135    1]\n",
      " [ 173    3 1433    0]\n",
      " [ 122    2  100    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6907840264951277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      1195\n",
      "           1       0.44      0.05      0.08       333\n",
      "           2       0.71      0.85      0.77      1609\n",
      "           3       0.41      0.11      0.17       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.53      0.41      0.41      3364\n",
      "weighted avg       0.62      0.65      0.61      3364\n",
      "\n",
      "[[ 782   11  387   15]\n",
      " [ 192   15  115   11]\n",
      " [ 230    4 1366    9]\n",
      " [ 131    4   68   24]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8793707407171518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.61      1195\n",
      "           1       0.36      0.09      0.14       333\n",
      "           2       0.73      0.83      0.78      1609\n",
      "           3       0.39      0.14      0.21       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.51      0.43      0.43      3364\n",
      "weighted avg       0.61      0.65      0.62      3364\n",
      "\n",
      "[[ 784   36  353   22]\n",
      " [ 196   29   92   16]\n",
      " [ 248    6 1342   13]\n",
      " [ 129   10   56   32]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.6519966881090377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.63      0.93      0.75      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.31      0.36      0.33      3364\n",
      "weighted avg       0.52      0.62      0.56      3364\n",
      "\n",
      "[[ 608    0  587    0]\n",
      " [ 176    0  157    0]\n",
      " [ 117    0 1492    0]\n",
      " [  83    0  144    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7523724603528438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1195\n",
      "           1       0.39      0.04      0.07       333\n",
      "           2       0.73      0.83      0.78      1609\n",
      "           3       0.49      0.19      0.27       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.55      0.43      0.44      3364\n",
      "weighted avg       0.62      0.65      0.62      3364\n",
      "\n",
      "[[ 814   14  349   18]\n",
      " [ 211   13   88   21]\n",
      " [ 276    0 1328    5]\n",
      " [ 129    6   49   43]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,1), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "538ee3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6893828418572066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51      1195\n",
      "           1       0.27      0.12      0.17       333\n",
      "           2       0.63      0.83      0.72      1609\n",
      "           3       0.31      0.08      0.13       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.44      0.38      0.38      3364\n",
      "weighted avg       0.55      0.58      0.55      3364\n",
      "\n",
      "[[ 577   55  543   20]\n",
      " [ 143   40  137   13]\n",
      " [ 243   27 1330    9]\n",
      " [  89   26   93   19]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.44      0.46      1195\n",
      "           1       0.17      0.14      0.15       333\n",
      "           2       0.61      0.72      0.66      1609\n",
      "           3       0.21      0.14      0.17       227\n",
      "\n",
      "    accuracy                           0.52      3364\n",
      "   macro avg       0.37      0.36      0.36      3364\n",
      "weighted avg       0.50      0.52      0.50      3364\n",
      "\n",
      "[[ 522  117  495   61]\n",
      " [ 130   45  135   23]\n",
      " [ 355   72 1151   31]\n",
      " [  78   24   94   31]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      1195\n",
      "           1       0.64      0.03      0.05       333\n",
      "           2       0.65      0.90      0.75      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.73      0.38      0.36      3364\n",
      "weighted avg       0.66      0.64      0.58      3364\n",
      "\n",
      "[[ 691    1  503    0]\n",
      " [ 168    9  156    0]\n",
      " [ 161    2 1446    0]\n",
      " [ 101    2  121    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6450544551302465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.47      0.52      1195\n",
      "           1       0.32      0.02      0.03       333\n",
      "           2       0.61      0.90      0.73      1609\n",
      "           3       0.57      0.11      0.18       227\n",
      "\n",
      "    accuracy                           0.61      3364\n",
      "   macro avg       0.52      0.37      0.37      3364\n",
      "weighted avg       0.58      0.61      0.55      3364\n",
      "\n",
      "[[ 557    7  620   11]\n",
      " [ 147    6  175    5]\n",
      " [ 148    4 1454    3]\n",
      " [  82    2  118   25]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.7677854913699764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55      1195\n",
      "           1       0.32      0.05      0.09       333\n",
      "           2       0.65      0.87      0.74      1609\n",
      "           3       0.53      0.12      0.20       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.52      0.39      0.40      3364\n",
      "weighted avg       0.58      0.62      0.57      3364\n",
      "\n",
      "[[ 634   23  520   18]\n",
      " [ 161   17  149    6]\n",
      " [ 204    7 1397    1]\n",
      " [ 105    6   88   28]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7212279472645055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.35      0.46      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.30      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 423    0  772    0]\n",
      " [ 124    0  209    0]\n",
      " [  37    0 1572    0]\n",
      " [  43    0  184    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.959938857397618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1195\n",
      "           1       0.47      0.03      0.05       333\n",
      "           2       0.72      0.83      0.77      1609\n",
      "           3       0.43      0.09      0.15       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.55      0.41      0.40      3364\n",
      "weighted avg       0.62      0.65      0.60      3364\n",
      "\n",
      "[[ 814    4  363   14]\n",
      " [ 211    9  102   11]\n",
      " [ 265    3 1339    2]\n",
      " [ 140    3   64   20]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(2,2), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12e278e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7007833895930196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.58      0.56      1195\n",
      "           1       0.26      0.12      0.16       333\n",
      "           2       0.68      0.78      0.72      1609\n",
      "           3       0.29      0.11      0.15       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.44      0.39      0.40      3364\n",
      "weighted avg       0.56      0.59      0.57      3364\n",
      "\n",
      "[[ 689   60  414   32]\n",
      " [ 175   39  101   18]\n",
      " [ 323   29 1247   10]\n",
      " [  99   24   80   24]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.46      0.46      1195\n",
      "           1       0.18      0.17      0.18       333\n",
      "           2       0.63      0.64      0.64      1609\n",
      "           3       0.14      0.12      0.13       227\n",
      "\n",
      "    accuracy                           0.50      3364\n",
      "   macro avg       0.35      0.35      0.35      3364\n",
      "weighted avg       0.49      0.50      0.49      3364\n",
      "\n",
      "[[ 550  139  429   77]\n",
      " [ 138   58  104   33]\n",
      " [ 419   95 1035   60]\n",
      " [ 100   33   66   28]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58      1195\n",
      "           1       0.75      0.03      0.05       333\n",
      "           2       0.64      0.91      0.75      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.63      3364\n",
      "   macro avg       0.75      0.38      0.35      3364\n",
      "weighted avg       0.67      0.63      0.57      3364\n",
      "\n",
      "[[ 655    0  540    0]\n",
      " [ 172    9  152    0]\n",
      " [ 139    1 1469    0]\n",
      " [  96    2  126    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6898286733329088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61      1195\n",
      "           1       0.42      0.04      0.08       333\n",
      "           2       0.70      0.87      0.78      1609\n",
      "           3       0.48      0.15      0.23       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.55      0.42      0.42      3364\n",
      "weighted avg       0.62      0.65      0.61      3364\n",
      "\n",
      "[[ 738   13  424   20]\n",
      " [ 190   14  119   10]\n",
      " [ 191    4 1406    8]\n",
      " [ 120    2   70   35]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8773963441818993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61      1195\n",
      "           1       0.39      0.10      0.15       333\n",
      "           2       0.71      0.85      0.77      1609\n",
      "           3       0.45      0.19      0.27       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.53      0.44      0.45      3364\n",
      "weighted avg       0.62      0.65      0.62      3364\n",
      "\n",
      "[[ 746   32  385   32]\n",
      " [ 182   32  109   10]\n",
      " [ 230    7 1361   11]\n",
      " [ 112   12   59   44]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.6727596968345966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.37      0.48      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.58      0.97      0.73      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.60      3364\n",
      "   macro avg       0.31      0.34      0.30      3364\n",
      "weighted avg       0.52      0.60      0.52      3364\n",
      "\n",
      "[[ 447    0  748    0]\n",
      " [ 134    0  199    0]\n",
      " [  41    0 1568    0]\n",
      " [  49    0  178    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9208330679574549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64      1195\n",
      "           1       0.47      0.05      0.09       333\n",
      "           2       0.75      0.83      0.79      1609\n",
      "           3       0.45      0.17      0.24       227\n",
      "\n",
      "    accuracy                           0.66      3364\n",
      "   macro avg       0.56      0.44      0.44      3364\n",
      "weighted avg       0.64      0.66      0.63      3364\n",
      "\n",
      "[[ 843   10  323   19]\n",
      " [ 207   16   89   21]\n",
      " [ 261    3 1339    6]\n",
      " [ 139    5   45   38]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,2), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47bcafae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6805299025539775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.46      1195\n",
      "           1       0.18      0.08      0.11       333\n",
      "           2       0.59      0.81      0.68      1609\n",
      "           3       0.38      0.07      0.11       227\n",
      "\n",
      "    accuracy                           0.55      3364\n",
      "   macro avg       0.41      0.34      0.34      3364\n",
      "weighted avg       0.51      0.55      0.51      3364\n",
      "\n",
      "[[ 501   57  620   17]\n",
      " [ 135   26  167    5]\n",
      " [ 262   41 1303    3]\n",
      " [  68   24  120   15]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49      1195\n",
      "           1       0.18      0.11      0.14       333\n",
      "           2       0.62      0.67      0.65      1609\n",
      "           3       0.17      0.11      0.13       227\n",
      "\n",
      "    accuracy                           0.52      3364\n",
      "   macro avg       0.36      0.35      0.35      3364\n",
      "weighted avg       0.50      0.52      0.51      3364\n",
      "\n",
      "[[ 604   82  456   53]\n",
      " [ 143   38  129   23]\n",
      " [ 415   69 1085   40]\n",
      " [ 100   22   81   24]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.32      0.42      1195\n",
      "           1       0.45      0.03      0.05       333\n",
      "           2       0.56      0.93      0.70      1609\n",
      "           3       0.50      0.04      0.07       227\n",
      "\n",
      "    accuracy                           0.56      3364\n",
      "   macro avg       0.53      0.33      0.31      3364\n",
      "weighted avg       0.56      0.56      0.49      3364\n",
      "\n",
      "[[ 387    4  799    5]\n",
      " [  98    9  225    1]\n",
      " [ 109    3 1495    2]\n",
      " [  54    4  161    8]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.5700910770014649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.22      0.33      1195\n",
      "           1       0.35      0.03      0.05       333\n",
      "           2       0.53      0.96      0.68      1609\n",
      "           3       0.52      0.05      0.10       227\n",
      "\n",
      "    accuracy                           0.54      3364\n",
      "   macro avg       0.51      0.31      0.29      3364\n",
      "weighted avg       0.55      0.54      0.45      3364\n",
      "\n",
      "[[ 263   11  913    8]\n",
      " [  62    9  261    1]\n",
      " [  67    3 1537    2]\n",
      " [  29    3  183   12]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.6582383287688682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.33      1195\n",
      "           1       0.17      0.02      0.03       333\n",
      "           2       0.53      0.94      0.68      1609\n",
      "           3       0.46      0.07      0.12       227\n",
      "\n",
      "    accuracy                           0.54      3364\n",
      "   macro avg       0.44      0.31      0.29      3364\n",
      "weighted avg       0.52      0.54      0.46      3364\n",
      "\n",
      "[[ 273   14  894   14]\n",
      " [  68    6  256    3]\n",
      " [  80   10 1517    2]\n",
      " [  30    5  176   16]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.8195656327622445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.26      0.38      1195\n",
      "           1       0.67      0.01      0.01       333\n",
      "           2       0.54      0.98      0.70      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.56      3364\n",
      "   macro avg       0.73      0.32      0.28      3364\n",
      "weighted avg       0.64      0.56      0.47      3364\n",
      "\n",
      "[[ 313    0  882    0]\n",
      " [  79    2  252    0]\n",
      " [  30    0 1579    0]\n",
      " [  31    1  192    3]]\n",
      "SVC(kernel='linear')\n",
      "Training accuracy: 0.9924208649130629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55      1195\n",
      "           1       0.50      0.02      0.04       333\n",
      "           2       0.63      0.87      0.73      1609\n",
      "           3       0.70      0.03      0.06       227\n",
      "\n",
      "    accuracy                           0.61      3364\n",
      "   macro avg       0.60      0.36      0.34      3364\n",
      "weighted avg       0.60      0.61      0.55      3364\n",
      "\n",
      "[[ 633    3  558    1]\n",
      " [ 173    7  151    2]\n",
      " [ 206    1 1402    0]\n",
      " [ 106    3  111    7]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(3,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26a77b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7026940959174575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.54      1195\n",
      "           1       0.22      0.10      0.13       333\n",
      "           2       0.67      0.78      0.72      1609\n",
      "           3       0.23      0.07      0.11       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.41      0.38      0.38      3364\n",
      "weighted avg       0.54      0.59      0.56      3364\n",
      "\n",
      "[[ 666   60  439   30]\n",
      " [ 170   32  113   18]\n",
      " [ 319   25 1258    7]\n",
      " [ 108   26   77   16]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.45      1195\n",
      "           1       0.14      0.15      0.15       333\n",
      "           2       0.62      0.64      0.63      1609\n",
      "           3       0.15      0.15      0.15       227\n",
      "\n",
      "    accuracy                           0.48      3364\n",
      "   macro avg       0.34      0.34      0.34      3364\n",
      "weighted avg       0.48      0.48      0.48      3364\n",
      "\n",
      "[[ 518  148  433   96]\n",
      " [ 132   49  124   28]\n",
      " [ 403  111 1027   68]\n",
      " [  80   33   80   34]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.47      0.55      1195\n",
      "           1       0.73      0.02      0.05       333\n",
      "           2       0.61      0.95      0.75      1609\n",
      "           3       0.75      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.69      0.36      0.34      3364\n",
      "weighted avg       0.65      0.62      0.56      3364\n",
      "\n",
      "[[ 558    0  637    0]\n",
      " [ 137    8  187    1]\n",
      " [  78    1 1530    0]\n",
      " [  79    2  143    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6902108145977963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58      1195\n",
      "           1       0.38      0.05      0.09       333\n",
      "           2       0.68      0.89      0.77      1609\n",
      "           3       0.45      0.17      0.24       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.53      0.42      0.42      3364\n",
      "weighted avg       0.61      0.64      0.60      3364\n",
      "\n",
      "[[ 675   20  476   24]\n",
      " [ 178   18  125   12]\n",
      " [ 157    4 1437   11]\n",
      " [ 108    5   76   38]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8745302846952423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.58      1195\n",
      "           1       0.31      0.09      0.14       333\n",
      "           2       0.70      0.87      0.78      1609\n",
      "           3       0.37      0.22      0.27       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.50      0.44      0.44      3364\n",
      "weighted avg       0.60      0.64      0.61      3364\n",
      "\n",
      "[[ 670   42  434   49]\n",
      " [ 177   31  105   20]\n",
      " [ 181   11 1404   13]\n",
      " [ 105   15   58   49]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7130119100694223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.34      0.46      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.29      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 411    0  784    0]\n",
      " [ 121    0  212    0]\n",
      " [  34    0 1575    0]\n",
      " [  45    0  182    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9638876504681231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64      1195\n",
      "           1       0.41      0.04      0.07       333\n",
      "           2       0.75      0.83      0.79      1609\n",
      "           3       0.48      0.17      0.25       227\n",
      "\n",
      "    accuracy                           0.66      3364\n",
      "   macro avg       0.56      0.44      0.44      3364\n",
      "weighted avg       0.64      0.66      0.63      3364\n",
      "\n",
      "[[ 852   10  314   19]\n",
      " [ 215   12   87   19]\n",
      " [ 268    3 1335    3]\n",
      " [ 143    4   42   38]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dc8599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6860709508948475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.44      0.48      1195\n",
      "           1       0.21      0.10      0.13       333\n",
      "           2       0.61      0.82      0.70      1609\n",
      "           3       0.25      0.06      0.09       227\n",
      "\n",
      "    accuracy                           0.56      3364\n",
      "   macro avg       0.40      0.35      0.35      3364\n",
      "weighted avg       0.52      0.56      0.52      3364\n",
      "\n",
      "[[ 528   66  584   17]\n",
      " [ 143   33  144   13]\n",
      " [ 256   33 1312    8]\n",
      " [  82   26  106   13]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.41      0.44      1195\n",
      "           1       0.20      0.16      0.18       333\n",
      "           2       0.60      0.71      0.65      1609\n",
      "           3       0.19      0.17      0.18       227\n",
      "\n",
      "    accuracy                           0.51      3364\n",
      "   macro avg       0.37      0.36      0.36      3364\n",
      "weighted avg       0.49      0.51      0.50      3364\n",
      "\n",
      "[[ 484  102  526   83]\n",
      " [ 106   54  143   30]\n",
      " [ 325   89 1150   45]\n",
      " [  71   21   97   38]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.54      1195\n",
      "           1       0.75      0.03      0.05       333\n",
      "           2       0.62      0.93      0.74      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.75      0.36      0.34      3364\n",
      "weighted avg       0.66      0.62      0.55      3364\n",
      "\n",
      "[[ 567    0  628    0]\n",
      " [ 151    9  173    0]\n",
      " [ 106    1 1502    0]\n",
      " [  94    2  128    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6450544551302465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.42      0.49      1195\n",
      "           1       0.24      0.03      0.05       333\n",
      "           2       0.60      0.91      0.73      1609\n",
      "           3       0.42      0.11      0.17       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.46      0.37      0.36      3364\n",
      "weighted avg       0.55      0.59      0.54      3364\n",
      "\n",
      "[[ 499   17  656   23]\n",
      " [ 135    9  182    7]\n",
      " [ 132    6 1466    5]\n",
      " [  76    6  120   25]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.7691229857970829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53      1195\n",
      "           1       0.30      0.06      0.10       333\n",
      "           2       0.64      0.90      0.75      1609\n",
      "           3       0.37      0.15      0.21       227\n",
      "\n",
      "    accuracy                           0.61      3364\n",
      "   macro avg       0.48      0.40      0.40      3364\n",
      "weighted avg       0.57      0.61      0.57      3364\n",
      "\n",
      "[[ 569   31  562   33]\n",
      " [ 140   21  154   18]\n",
      " [ 149   10 1444    6]\n",
      " [  86    9   99   33]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7642825297751735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.32      0.44      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.56      0.33      0.30      3364\n",
      "weighted avg       0.58      0.59      0.50      3364\n",
      "\n",
      "[[ 386    0  809    0]\n",
      " [ 112    0  221    0]\n",
      " [  29    0 1580    0]\n",
      " [  42    0  182    3]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9833131647665754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.67      0.62      1195\n",
      "           1       0.53      0.02      0.05       333\n",
      "           2       0.71      0.86      0.78      1609\n",
      "           3       0.47      0.06      0.11       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.57      0.40      0.39      3364\n",
      "weighted avg       0.63      0.65      0.60      3364\n",
      "\n",
      "[[ 799    1  387    8]\n",
      " [ 208    8  109    8]\n",
      " [ 225    3 1381    0]\n",
      " [ 141    3   69   14]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(2,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ffe8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7025030252850137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53      1195\n",
      "           1       0.21      0.09      0.13       333\n",
      "           2       0.66      0.76      0.71      1609\n",
      "           3       0.31      0.09      0.14       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.42      0.38      0.38      3364\n",
      "weighted avg       0.54      0.58      0.55      3364\n",
      "\n",
      "[[ 664   60  446   25]\n",
      " [ 177   31  110   15]\n",
      " [ 343   35 1224    7]\n",
      " [ 111   20   75   21]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.43      0.44      1195\n",
      "           1       0.17      0.19      0.18       333\n",
      "           2       0.61      0.61      0.61      1609\n",
      "           3       0.16      0.14      0.15       227\n",
      "\n",
      "    accuracy                           0.47      3364\n",
      "   macro avg       0.34      0.34      0.34      3364\n",
      "weighted avg       0.47      0.47      0.47      3364\n",
      "\n",
      "[[514 146 443  92]\n",
      " [130  63 113  27]\n",
      " [437 131 988  53]\n",
      " [ 87  27  81  32]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.46      0.54      1195\n",
      "           1       0.75      0.03      0.05       333\n",
      "           2       0.61      0.95      0.74      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.75      0.36      0.34      3364\n",
      "weighted avg       0.66      0.62      0.55      3364\n",
      "\n",
      "[[ 548    0  647    0]\n",
      " [ 145    9  179    0]\n",
      " [  79    1 1529    0]\n",
      " [  75    2  147    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.689956053754538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56      1195\n",
      "           1       0.34      0.04      0.07       333\n",
      "           2       0.67      0.90      0.77      1609\n",
      "           3       0.39      0.21      0.27       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.50      0.42      0.42      3364\n",
      "weighted avg       0.60      0.64      0.59      3364\n",
      "\n",
      "[[ 634   16  499   46]\n",
      " [ 171   14  132   16]\n",
      " [ 144    5 1446   14]\n",
      " [ 101    6   72   48]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.873320170689765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56      1195\n",
      "           1       0.27      0.11      0.16       333\n",
      "           2       0.69      0.88      0.78      1609\n",
      "           3       0.40      0.24      0.30       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.49      0.44      0.45      3364\n",
      "weighted avg       0.60      0.64      0.61      3364\n",
      "\n",
      "[[ 625   65  449   56]\n",
      " [ 163   37  117   16]\n",
      " [ 162   13 1422   12]\n",
      " [  92   21   59   55]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7475320043309344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.34      0.45      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.29      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 406    0  789    0]\n",
      " [ 117    0  216    0]\n",
      " [  33    0 1576    0]\n",
      " [  39    0  188    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.975925100312082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.64      1195\n",
      "           1       0.44      0.04      0.07       333\n",
      "           2       0.76      0.82      0.79      1609\n",
      "           3       0.48      0.16      0.24       227\n",
      "\n",
      "    accuracy                           0.66      3364\n",
      "   macro avg       0.56      0.44      0.43      3364\n",
      "weighted avg       0.64      0.66      0.63      3364\n",
      "\n",
      "[[ 866    8  301   20]\n",
      " [ 218   12   86   17]\n",
      " [ 287    3 1316    3]\n",
      " [ 146    4   40   37]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,4), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb102a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nr_features(t):\n",
    "    # create a TF-IDF vectorizer with desired configurations\n",
    "    vectorizer = TfidfVectorizer(ngram_range=t)\n",
    "    # fit and transform the text data\n",
    "    tfidf_matrix = vectorizer.fit_transform(X_train)\n",
    "    # get the number of features\n",
    "    num_features = len(vectorizer.get_feature_names_out())\n",
    "    print(\"Number of features when n-gram is {ng}: {nf}\".format(ng=t,nf=num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbc195eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features when n-gram is (1, 1): 21021\n",
      "Number of features when n-gram is (1, 2): 388817\n",
      "Number of features when n-gram is (2, 2): 367796\n",
      "Number of features when n-gram is (1, 3): 1212232\n",
      "Number of features when n-gram is (3, 3): 823415\n",
      "Number of features when n-gram is (2, 3): 1191211\n",
      "Number of features when n-gram is (1, 4): 2193025\n"
     ]
    }
   ],
   "source": [
    "nr_features((1,1))\n",
    "nr_features((1,2))\n",
    "nr_features((2,2))\n",
    "nr_features((1,3))\n",
    "nr_features((3,3))\n",
    "nr_features((2,3))\n",
    "nr_features((1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b753ad18",
   "metadata": {},
   "source": [
    "The max_df parameter in the TF-IDF vectorizer specifies the threshold value for document frequency, beyond which terms will be ignored. This parameter can be used to remove words that are too common and may not be informative for text classification. However, setting max_df too low can also result in the removal of important words.\n",
    "\n",
    "Choosing an appropriate max_df value can be somewhat subjective and may depend on the specific text dataset and the classification task. A common approach is to start with a value of 0.95 and gradually reduce it until the desired number of features is obtained. If the corpus is small, choose a smaller max_df value (e.g., 0.5 or lower) to avoid overfitting.\n",
    "If the corpus is large, choose a higher max_df value (e.g., 0.9 or higher) to remove common words and reduce dimensionality.\n",
    "If the text dataset contains many rare words or is noisy, it may be necessary to set max_df to a lower value to remove those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c49465cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words: 25140\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Get the number of unique words in the complaints\n",
    "unique_words = set(\" \".join(df['narrative_tfidf']).split())\n",
    "print(\"Number of unique words:\", len(unique_words))\n",
    "\n",
    "# Get the frequency of the words in the complaints\n",
    "word_freq = Counter(\" \".join(df['narrative_tfidf']).split())\n",
    "# print(\"Frequency of words:\", word_freq)\n",
    "\n",
    "# Get the length of each complaint\n",
    "complaint_lengths = [len(x.split()) for x in df['narrative_tfidf']]\n",
    "# print(\"Length of complaints:\", complaint_lengths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5d1be",
   "metadata": {},
   "source": [
    "# with scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c6db304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training2(clf,X_train, X_val, y_train, y_val,ngram, maxf):\n",
    "    ngram=ngram #tuplo\n",
    "    maxf=maxf\n",
    "    \n",
    "    # Perform tf-idf vectorization on the training set\n",
    "    tfidf = TfidfVectorizer(ngram_range=ngram, max_features=maxf)\n",
    "    X_train_tf = tfidf.fit_transform(X_train)\n",
    "    \n",
    "    # Use the same vectorizer to transform the validation set\n",
    "    X_val_tf = tfidf.transform(X_val)\n",
    "    \n",
    "    from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "   # ValueError: Negative values in data passed to MultinomialNB (input X) if standard scaler is used!!!\n",
    "    # use to_array if sparse matrix\n",
    "    # no memory available for to_array()\n",
    "    scaler = MaxAbsScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_tf)\n",
    "    X_val_scaled= scaler.transform(X_val_tf)\n",
    "\n",
    "    #Train classifier on the training set\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict the labels on the validation set\n",
    "    y_val_pred = clf.predict(X_val_scaled)\n",
    "    # Predict the labels on the train set\n",
    "    y_train_pred = clf.predict(X_train_scaled) \n",
    "\n",
    "    # Compute the accuracy of the model on the training set\n",
    "    acc_val = accuracy_score(y_train, y_train_pred)\n",
    "    print(\"Training accuracy:\", acc_val)\n",
    "    \n",
    "    return classification_report(y_val, y_val_pred), confusion_matrix(y_val, y_val_pred, labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d24955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7036494490796764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.57      0.55      1195\n",
      "           1       0.24      0.11      0.15       333\n",
      "           2       0.67      0.76      0.71      1609\n",
      "           3       0.25      0.10      0.14       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.42      0.38      0.39      3364\n",
      "weighted avg       0.55      0.58      0.56      3364\n",
      "\n",
      "[[ 687   61  411   36]\n",
      " [ 173   35  107   18]\n",
      " [ 350   29 1215   15]\n",
      " [  99   22   83   23]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.49      0.47      1195\n",
      "           1       0.17      0.15      0.16       333\n",
      "           2       0.64      0.64      0.64      1609\n",
      "           3       0.16      0.14      0.15       227\n",
      "\n",
      "    accuracy                           0.51      3364\n",
      "   macro avg       0.36      0.36      0.36      3364\n",
      "weighted avg       0.50      0.51      0.50      3364\n",
      "\n",
      "[[ 581  129  405   80]\n",
      " [ 161   51   94   27]\n",
      " [ 427   87 1037   58]\n",
      " [  85   29   82   31]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.63      0.62      1195\n",
      "           1       0.62      0.02      0.05       333\n",
      "           2       0.67      0.89      0.77      1609\n",
      "           3       0.75      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.66      0.39      0.36      3364\n",
      "weighted avg       0.65      0.65      0.59      3364\n",
      "\n",
      "[[ 751    0  444    0]\n",
      " [ 180    8  144    1]\n",
      " [ 177    3 1429    0]\n",
      " [ 119    2  103    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6874721355327686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.65      0.61      1195\n",
      "           1       0.33      0.03      0.06       333\n",
      "           2       0.71      0.85      0.77      1609\n",
      "           3       0.42      0.10      0.16       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.51      0.41      0.40      3364\n",
      "weighted avg       0.61      0.65      0.60      3364\n",
      "\n",
      "[[ 779   14  388   14]\n",
      " [ 199   11  112   11]\n",
      " [ 231    4 1367    7]\n",
      " [ 133    4   67   23]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8793707407171518\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.66      0.61      1195\n",
      "           1       0.36      0.09      0.14       333\n",
      "           2       0.73      0.83      0.78      1609\n",
      "           3       0.39      0.14      0.21       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.51      0.43      0.43      3364\n",
      "weighted avg       0.61      0.65      0.62      3364\n",
      "\n",
      "[[ 784   36  353   22]\n",
      " [ 196   29   92   16]\n",
      " [ 248    6 1342   13]\n",
      " [ 129   10   56   32]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.6519966881090377\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.51      0.56      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.63      0.93      0.75      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.31      0.36      0.33      3364\n",
      "weighted avg       0.52      0.62      0.56      3364\n",
      "\n",
      "[[ 608    0  587    0]\n",
      " [ 176    0  157    0]\n",
      " [ 117    0 1492    0]\n",
      " [  83    0  144    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.7523724603528438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1195\n",
      "           1       0.39      0.04      0.07       333\n",
      "           2       0.73      0.83      0.78      1609\n",
      "           3       0.49      0.19      0.27       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.55      0.43      0.44      3364\n",
      "weighted avg       0.62      0.65      0.62      3364\n",
      "\n",
      "[[ 814   14  349   18]\n",
      " [ 211   13   88   21]\n",
      " [ 276    0 1328    5]\n",
      " [ 129    6   49   43]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,1), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097410f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6893828418572066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.48      0.51      1195\n",
      "           1       0.27      0.12      0.17       333\n",
      "           2       0.63      0.83      0.72      1609\n",
      "           3       0.31      0.08      0.13       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.44      0.38      0.38      3364\n",
      "weighted avg       0.55      0.58      0.55      3364\n",
      "\n",
      "[[ 577   55  543   20]\n",
      " [ 143   40  137   13]\n",
      " [ 243   27 1330    9]\n",
      " [  89   26   93   19]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.43      0.46      1195\n",
      "           1       0.18      0.15      0.17       333\n",
      "           2       0.61      0.72      0.66      1609\n",
      "           3       0.22      0.15      0.17       227\n",
      "\n",
      "    accuracy                           0.52      3364\n",
      "   macro avg       0.38      0.36      0.36      3364\n",
      "weighted avg       0.50      0.52      0.51      3364\n",
      "\n",
      "[[ 514  120  499   62]\n",
      " [ 127   50  137   19]\n",
      " [ 332   83 1156   38]\n",
      " [  83   20   91   33]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.57      0.59      1195\n",
      "           1       0.67      0.02      0.05       333\n",
      "           2       0.65      0.90      0.75      1609\n",
      "           3       0.75      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.67      0.38      0.35      3364\n",
      "weighted avg       0.64      0.64      0.58      3364\n",
      "\n",
      "[[ 681    0  514    0]\n",
      " [ 166    8  158    1]\n",
      " [ 160    2 1447    0]\n",
      " [ 107    2  115    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6441627921788421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.46      0.52      1195\n",
      "           1       0.30      0.02      0.03       333\n",
      "           2       0.61      0.90      0.73      1609\n",
      "           3       0.55      0.11      0.18       227\n",
      "\n",
      "    accuracy                           0.60      3364\n",
      "   macro avg       0.51      0.37      0.37      3364\n",
      "weighted avg       0.57      0.60      0.55      3364\n",
      "\n",
      "[[ 555    8  620   12]\n",
      " [ 147    6  175    5]\n",
      " [ 155    4 1447    3]\n",
      " [  78    2  123   24]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.7677854913699764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55      1195\n",
      "           1       0.32      0.05      0.09       333\n",
      "           2       0.65      0.87      0.74      1609\n",
      "           3       0.53      0.12      0.20       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.52      0.39      0.40      3364\n",
      "weighted avg       0.58      0.62      0.57      3364\n",
      "\n",
      "[[ 634   23  520   18]\n",
      " [ 161   17  149    6]\n",
      " [ 204    7 1397    1]\n",
      " [ 105    6   88   28]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7212279472645055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.35      0.46      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.30      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 423    0  772    0]\n",
      " [ 124    0  209    0]\n",
      " [  37    0 1572    0]\n",
      " [  43    0  184    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.959938857397618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.68      0.62      1195\n",
      "           1       0.47      0.03      0.05       333\n",
      "           2       0.72      0.83      0.77      1609\n",
      "           3       0.43      0.09      0.15       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.55      0.41      0.40      3364\n",
      "weighted avg       0.62      0.65      0.60      3364\n",
      "\n",
      "[[ 814    4  363   14]\n",
      " [ 211    9  102   11]\n",
      " [ 265    3 1339    2]\n",
      " [ 140    3   64   20]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(2,2), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22dd0a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.4971657856187504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.01      0.02      1195\n",
      "           1       0.44      0.01      0.02       333\n",
      "           2       0.48      0.99      0.65      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.48      3364\n",
      "   macro avg       0.57      0.26      0.18      3364\n",
      "weighted avg       0.47      0.48      0.32      3364\n",
      "\n",
      "[[  12    0 1183    0]\n",
      " [   3    4  326    0]\n",
      " [  14    2 1593    0]\n",
      " [   3    3  218    3]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.45      0.46      1195\n",
      "           1       0.16      0.17      0.16       333\n",
      "           2       0.64      0.65      0.64      1609\n",
      "           3       0.19      0.16      0.17       227\n",
      "\n",
      "    accuracy                           0.50      3364\n",
      "   macro avg       0.36      0.36      0.36      3364\n",
      "weighted avg       0.50      0.50      0.50      3364\n",
      "\n",
      "[[ 541  150  427   77]\n",
      " [ 141   55  105   32]\n",
      " [ 413  106 1047   43]\n",
      " [  87   35   69   36]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.55      0.58      1195\n",
      "           1       0.69      0.03      0.05       333\n",
      "           2       0.64      0.92      0.76      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.74      0.38      0.35      3364\n",
      "weighted avg       0.66      0.64      0.58      3364\n",
      "\n",
      "[[ 656    0  539    0]\n",
      " [ 165    9  159    0]\n",
      " [ 133    2 1474    0]\n",
      " [ 102    2  120    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.689000700592319\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60      1195\n",
      "           1       0.44      0.04      0.08       333\n",
      "           2       0.69      0.87      0.77      1609\n",
      "           3       0.43      0.13      0.20       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.54      0.41      0.41      3364\n",
      "weighted avg       0.61      0.65      0.60      3364\n",
      "\n",
      "[[ 729   14  433   19]\n",
      " [ 190   14  118   11]\n",
      " [ 197    1 1402    9]\n",
      " [ 125    3   70   29]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8773963441818993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.62      0.61      1195\n",
      "           1       0.39      0.10      0.15       333\n",
      "           2       0.71      0.85      0.77      1609\n",
      "           3       0.45      0.19      0.27       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.53      0.44      0.45      3364\n",
      "weighted avg       0.62      0.65      0.62      3364\n",
      "\n",
      "[[ 746   32  385   32]\n",
      " [ 182   32  109   10]\n",
      " [ 230    7 1361   11]\n",
      " [ 112   12   59   44]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.9233806763900388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.60      0.60      1195\n",
      "           1       0.56      0.02      0.03       333\n",
      "           2       0.66      0.89      0.76      1609\n",
      "           3       1.00      0.02      0.03       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.70      0.38      0.36      3364\n",
      "weighted avg       0.65      0.64      0.58      3364\n",
      "\n",
      "[[ 714    3  478    0]\n",
      " [ 188    5  140    0]\n",
      " [ 178    1 1430    0]\n",
      " [ 115    0  108    4]]\n",
      "SVC(kernel='linear')\n",
      "Training accuracy: 0.9992357174702248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62      1195\n",
      "           1       0.26      0.08      0.13       333\n",
      "           2       0.74      0.80      0.77      1609\n",
      "           3       0.41      0.20      0.27       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.50      0.44      0.45      3364\n",
      "weighted avg       0.61      0.64      0.62      3364\n",
      "\n",
      "[[ 801   43  315   36]\n",
      " [ 194   28   87   24]\n",
      " [ 297   16 1289    7]\n",
      " [ 117   20   44   46]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training2(classifier,X_train, X_val, y_train, y_val,(1,2), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3c46292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6805299025539775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.42      0.46      1195\n",
      "           1       0.18      0.08      0.11       333\n",
      "           2       0.59      0.81      0.68      1609\n",
      "           3       0.38      0.07      0.11       227\n",
      "\n",
      "    accuracy                           0.55      3364\n",
      "   macro avg       0.41      0.34      0.34      3364\n",
      "weighted avg       0.51      0.55      0.51      3364\n",
      "\n",
      "[[ 501   57  620   17]\n",
      " [ 135   26  167    5]\n",
      " [ 262   41 1303    3]\n",
      " [  68   24  120   15]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.51      0.49      1195\n",
      "           1       0.17      0.10      0.13       333\n",
      "           2       0.62      0.67      0.64      1609\n",
      "           3       0.17      0.12      0.14       227\n",
      "\n",
      "    accuracy                           0.52      3364\n",
      "   macro avg       0.36      0.35      0.35      3364\n",
      "weighted avg       0.50      0.52      0.50      3364\n",
      "\n",
      "[[ 609   75  451   60]\n",
      " [ 156   34  123   20]\n",
      " [ 419   64 1073   53]\n",
      " [  96   22   81   28]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9992357174702248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.33      0.43      1195\n",
      "           1       0.45      0.03      0.05       333\n",
      "           2       0.56      0.94      0.70      1609\n",
      "           3       0.57      0.04      0.07       227\n",
      "\n",
      "    accuracy                           0.57      3364\n",
      "   macro avg       0.55      0.33      0.31      3364\n",
      "weighted avg       0.57      0.57      0.50      3364\n",
      "\n",
      "[[ 389    3  799    4]\n",
      " [  90    9  233    1]\n",
      " [  93    5 1510    1]\n",
      " [  53    3  163    8]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.5695815553149481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.22      0.33      1195\n",
      "           1       0.33      0.03      0.05       333\n",
      "           2       0.53      0.96      0.68      1609\n",
      "           3       0.52      0.05      0.10       227\n",
      "\n",
      "    accuracy                           0.54      3364\n",
      "   macro avg       0.50      0.31      0.29      3364\n",
      "weighted avg       0.55      0.54      0.46      3364\n",
      "\n",
      "[[ 267   12  909    7]\n",
      " [  63    9  260    1]\n",
      " [  65    3 1538    3]\n",
      " [  30    3  182   12]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.6582383287688682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.23      0.33      1195\n",
      "           1       0.17      0.02      0.03       333\n",
      "           2       0.53      0.94      0.68      1609\n",
      "           3       0.46      0.07      0.12       227\n",
      "\n",
      "    accuracy                           0.54      3364\n",
      "   macro avg       0.44      0.31      0.29      3364\n",
      "weighted avg       0.52      0.54      0.46      3364\n",
      "\n",
      "[[ 273   14  894   14]\n",
      " [  68    6  256    3]\n",
      " [  80   10 1517    2]\n",
      " [  30    5  176   16]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.8195656327622445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.26      0.38      1195\n",
      "           1       0.67      0.01      0.01       333\n",
      "           2       0.54      0.98      0.70      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.56      3364\n",
      "   macro avg       0.73      0.32      0.28      3364\n",
      "weighted avg       0.64      0.56      0.47      3364\n",
      "\n",
      "[[ 313    0  882    0]\n",
      " [  79    2  252    0]\n",
      " [  30    0 1579    0]\n",
      " [  31    1  192    3]]\n",
      "SVC(kernel='linear')\n",
      "Training accuracy: 0.9924208649130629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.53      0.55      1195\n",
      "           1       0.50      0.02      0.04       333\n",
      "           2       0.63      0.87      0.73      1609\n",
      "           3       0.70      0.03      0.06       227\n",
      "\n",
      "    accuracy                           0.61      3364\n",
      "   macro avg       0.60      0.36      0.34      3364\n",
      "weighted avg       0.60      0.61      0.55      3364\n",
      "\n",
      "[[ 633    3  558    1]\n",
      " [ 173    7  151    2]\n",
      " [ 206    1 1402    0]\n",
      " [ 106    3  111    7]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(3,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "071f6d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7026940959174575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.56      0.54      1195\n",
      "           1       0.22      0.10      0.13       333\n",
      "           2       0.67      0.78      0.72      1609\n",
      "           3       0.23      0.07      0.11       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.41      0.38      0.38      3364\n",
      "weighted avg       0.54      0.59      0.56      3364\n",
      "\n",
      "[[ 666   60  439   30]\n",
      " [ 170   32  113   18]\n",
      " [ 319   25 1258    7]\n",
      " [ 108   26   77   16]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.43      0.44      1195\n",
      "           1       0.15      0.16      0.16       333\n",
      "           2       0.62      0.65      0.64      1609\n",
      "           3       0.18      0.16      0.17       227\n",
      "\n",
      "    accuracy                           0.49      3364\n",
      "   macro avg       0.35      0.35      0.35      3364\n",
      "weighted avg       0.49      0.49      0.49      3364\n",
      "\n",
      "[[ 516  153  427   99]\n",
      " [ 129   54  127   23]\n",
      " [ 399  111 1047   52]\n",
      " [  81   33   76   37]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.50      0.57      1195\n",
      "           1       0.73      0.02      0.05       333\n",
      "           2       0.62      0.94      0.75      1609\n",
      "           3       0.75      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.63      3364\n",
      "   macro avg       0.69      0.37      0.35      3364\n",
      "weighted avg       0.65      0.63      0.57      3364\n",
      "\n",
      "[[ 597    0  598    0]\n",
      " [ 147    8  177    1]\n",
      " [  92    1 1516    0]\n",
      " [  81    2  141    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.689956053754538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.56      0.58      1195\n",
      "           1       0.38      0.05      0.09       333\n",
      "           2       0.68      0.89      0.77      1609\n",
      "           3       0.37      0.14      0.20       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.51      0.41      0.41      3364\n",
      "weighted avg       0.60      0.64      0.60      3364\n",
      "\n",
      "[[ 668   17  484   26]\n",
      " [ 174   17  128   14]\n",
      " [ 154    6 1437   12]\n",
      " [ 113    5   78   31]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.8745302846952423\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.58      1195\n",
      "           1       0.31      0.09      0.14       333\n",
      "           2       0.70      0.87      0.78      1609\n",
      "           3       0.37      0.22      0.27       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.50      0.44      0.44      3364\n",
      "weighted avg       0.60      0.64      0.61      3364\n",
      "\n",
      "[[ 670   42  434   49]\n",
      " [ 177   31  105   20]\n",
      " [ 181   11 1404   13]\n",
      " [ 105   15   58   49]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7130119100694223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.34      0.46      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.29      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 411    0  784    0]\n",
      " [ 121    0  212    0]\n",
      " [  34    0 1575    0]\n",
      " [  45    0  182    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9638876504681231\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64      1195\n",
      "           1       0.41      0.04      0.07       333\n",
      "           2       0.75      0.83      0.79      1609\n",
      "           3       0.48      0.17      0.25       227\n",
      "\n",
      "    accuracy                           0.66      3364\n",
      "   macro avg       0.56      0.44      0.44      3364\n",
      "weighted avg       0.64      0.66      0.63      3364\n",
      "\n",
      "[[ 852   10  314   19]\n",
      " [ 215   12   87   19]\n",
      " [ 268    3 1335    3]\n",
      " [ 143    4   42   38]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f7048e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.6860709508948475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.44      0.48      1195\n",
      "           1       0.21      0.10      0.13       333\n",
      "           2       0.61      0.82      0.70      1609\n",
      "           3       0.25      0.06      0.09       227\n",
      "\n",
      "    accuracy                           0.56      3364\n",
      "   macro avg       0.40      0.35      0.35      3364\n",
      "weighted avg       0.52      0.56      0.52      3364\n",
      "\n",
      "[[ 528   66  584   17]\n",
      " [ 143   33  144   13]\n",
      " [ 256   33 1312    8]\n",
      " [  82   26  106   13]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.40      0.44      1195\n",
      "           1       0.18      0.16      0.17       333\n",
      "           2       0.60      0.72      0.66      1609\n",
      "           3       0.19      0.15      0.17       227\n",
      "\n",
      "    accuracy                           0.51      3364\n",
      "   macro avg       0.37      0.36      0.36      3364\n",
      "weighted avg       0.49      0.51      0.50      3364\n",
      "\n",
      "[[ 473  114  534   74]\n",
      " [ 118   53  138   24]\n",
      " [ 290  103 1166   50]\n",
      " [  72   18  102   35]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.47      0.53      1195\n",
      "           1       0.73      0.02      0.05       333\n",
      "           2       0.62      0.93      0.74      1609\n",
      "           3       0.80      0.02      0.03       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.69      0.36      0.34      3364\n",
      "weighted avg       0.64      0.62      0.55      3364\n",
      "\n",
      "[[ 563    0  632    0]\n",
      " [ 151    8  173    1]\n",
      " [ 104    1 1504    0]\n",
      " [  93    2  128    4]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.6426979173301064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.42      0.49      1195\n",
      "           1       0.22      0.02      0.04       333\n",
      "           2       0.60      0.91      0.73      1609\n",
      "           3       0.44      0.12      0.19       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.46      0.37      0.36      3364\n",
      "weighted avg       0.55      0.59      0.54      3364\n",
      "\n",
      "[[ 501   18  652   24]\n",
      " [ 135    8  184    6]\n",
      " [ 138    5 1461    5]\n",
      " [  71    5  124   27]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.7691229857970829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.48      0.53      1195\n",
      "           1       0.30      0.06      0.10       333\n",
      "           2       0.64      0.90      0.75      1609\n",
      "           3       0.37      0.15      0.21       227\n",
      "\n",
      "    accuracy                           0.61      3364\n",
      "   macro avg       0.48      0.40      0.40      3364\n",
      "weighted avg       0.57      0.61      0.57      3364\n",
      "\n",
      "[[ 569   31  562   33]\n",
      " [ 140   21  154   18]\n",
      " [ 149   10 1444    6]\n",
      " [  86    9   99   33]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7642825297751735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.32      0.44      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.56      0.33      0.30      3364\n",
      "weighted avg       0.58      0.59      0.50      3364\n",
      "\n",
      "[[ 386    0  809    0]\n",
      " [ 112    0  221    0]\n",
      " [  29    0 1580    0]\n",
      " [  42    0  182    3]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9833131647665754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.67      0.62      1195\n",
      "           1       0.53      0.02      0.05       333\n",
      "           2       0.71      0.86      0.78      1609\n",
      "           3       0.47      0.06      0.11       227\n",
      "\n",
      "    accuracy                           0.65      3364\n",
      "   macro avg       0.57      0.40      0.39      3364\n",
      "weighted avg       0.63      0.65      0.60      3364\n",
      "\n",
      "[[ 799    1  387    8]\n",
      " [ 208    8  109    8]\n",
      " [ 225    3 1381    0]\n",
      " [ 141    3   69   14]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(2,3), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84f3599a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "Training accuracy: 0.7025030252850137\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.53      1195\n",
      "           1       0.21      0.09      0.13       333\n",
      "           2       0.66      0.76      0.71      1609\n",
      "           3       0.31      0.09      0.14       227\n",
      "\n",
      "    accuracy                           0.58      3364\n",
      "   macro avg       0.42      0.38      0.38      3364\n",
      "weighted avg       0.54      0.58      0.55      3364\n",
      "\n",
      "[[ 664   60  446   25]\n",
      " [ 177   31  110   15]\n",
      " [ 343   35 1224    7]\n",
      " [ 111   20   75   21]]\n",
      "DecisionTreeClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.42      0.42      1195\n",
      "           1       0.18      0.21      0.19       333\n",
      "           2       0.60      0.61      0.60      1609\n",
      "           3       0.18      0.16      0.17       227\n",
      "\n",
      "    accuracy                           0.47      3364\n",
      "   macro avg       0.35      0.35      0.35      3364\n",
      "weighted avg       0.47      0.47      0.47      3364\n",
      "\n",
      "[[496 157 454  88]\n",
      " [127  69 106  31]\n",
      " [462 123 974  50]\n",
      " [ 77  32  82  36]]\n",
      "RandomForestClassifier()\n",
      "Training accuracy: 0.9993630978918541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52      1195\n",
      "           1       0.75      0.03      0.05       333\n",
      "           2       0.60      0.95      0.74      1609\n",
      "           3       1.00      0.01      0.03       227\n",
      "\n",
      "    accuracy                           0.62      3364\n",
      "   macro avg       0.75      0.36      0.34      3364\n",
      "weighted avg       0.66      0.62      0.55      3364\n",
      "\n",
      "[[ 527    0  668    0]\n",
      " [ 137    9  187    0]\n",
      " [  78    1 1530    0]\n",
      " [  78    2  144    3]]\n",
      "GradientBoostingClassifier()\n",
      "Training accuracy: 0.689956053754538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.53      0.57      1195\n",
      "           1       0.33      0.04      0.07       333\n",
      "           2       0.67      0.90      0.77      1609\n",
      "           3       0.38      0.21      0.27       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.50      0.42      0.42      3364\n",
      "weighted avg       0.59      0.64      0.59      3364\n",
      "\n",
      "[[ 635   17  497   46]\n",
      " [ 170   14  131   18]\n",
      " [ 142    6 1447   14]\n",
      " [ 102    6   72   47]]\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "Training accuracy: 0.873320170689765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.52      0.56      1195\n",
      "           1       0.27      0.11      0.16       333\n",
      "           2       0.69      0.88      0.78      1609\n",
      "           3       0.40      0.24      0.30       227\n",
      "\n",
      "    accuracy                           0.64      3364\n",
      "   macro avg       0.49      0.44      0.45      3364\n",
      "weighted avg       0.60      0.64      0.61      3364\n",
      "\n",
      "[[ 625   65  449   56]\n",
      " [ 163   37  117   16]\n",
      " [ 162   13 1422   12]\n",
      " [  92   21   59   55]]\n",
      "MultinomialNB()\n",
      "Training accuracy: 0.7475320043309344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.34      0.45      1195\n",
      "           1       0.00      0.00      0.00       333\n",
      "           2       0.57      0.98      0.72      1609\n",
      "           3       0.00      0.00      0.00       227\n",
      "\n",
      "    accuracy                           0.59      3364\n",
      "   macro avg       0.31      0.33      0.29      3364\n",
      "weighted avg       0.51      0.59      0.51      3364\n",
      "\n",
      "[[ 406    0  789    0]\n",
      " [ 117    0  216    0]\n",
      " [  33    0 1576    0]\n",
      " [  39    0  188    0]]\n",
      "SVC(kernel='linear')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.975925100312082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.64      1195\n",
      "           1       0.44      0.04      0.07       333\n",
      "           2       0.76      0.82      0.79      1609\n",
      "           3       0.48      0.16      0.24       227\n",
      "\n",
      "    accuracy                           0.66      3364\n",
      "   macro avg       0.56      0.44      0.43      3364\n",
      "weighted avg       0.64      0.66      0.63      3364\n",
      "\n",
      "[[ 866    8  301   20]\n",
      " [ 218   12   86   17]\n",
      " [ 287    3 1316    3]\n",
      " [ 146    4   40   37]]\n"
     ]
    }
   ],
   "source": [
    "# cf: The columns will show the instances predicted for each label,\n",
    "# and the rows will show the actual number of instances for each label.\n",
    "for classifier in [KNeighborsClassifier(),DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(),\n",
    "                   XGBClassifier(), MultinomialNB(),SVC(kernel='linear')]:\n",
    "    print(classifier)\n",
    "    cm,cf=training(classifier,X_train, X_val, y_train, y_val,(1,4), maxf=None)\n",
    "    print(cm)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3025a083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features when n-gram is (1, 1): 21021\n",
      "Number of features when n-gram is (1, 2): 388817\n",
      "Number of features when n-gram is (2, 2): 367796\n",
      "Number of features when n-gram is (1, 3): 1212232\n",
      "Number of features when n-gram is (3, 3): 823415\n",
      "Number of features when n-gram is (2, 3): 1191211\n",
      "Number of features when n-gram is (1, 4): 2193025\n"
     ]
    }
   ],
   "source": [
    "nr_features((1,1))\n",
    "nr_features((1,2))\n",
    "nr_features((2,2))\n",
    "nr_features((1,3))\n",
    "nr_features((3,3))\n",
    "nr_features((2,3))\n",
    "nr_features((1,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17b27c",
   "metadata": {},
   "source": [
    "\"It's generally a good idea to scale your data after feature engineering, because feature engineering can significantly alter the distribution of your data and make it difficult to determine the appropriate scaling method. Scaling before feature engineering can also lead to the loss of important information, especially if you are using techniques that are sensitive to the distribution of the data, such as PCA or kernel methods.\n",
    "\n",
    "By performing feature engineering first, you can gain a better understanding of the distribution of your data and determine the appropriate scaling method based on the transformed features. For example, if you use a logarithmic transformation to make a feature more normally distributed, you may need to use a scaling method that is appropriate for normally distributed data, such as StandardScaler. On the other hand, if you use a quantile transformation to make a feature more uniformly distributed, you may need to use a scaling method that is appropriate for uniformly distributed data, such as MinMaxScaler.\n",
    "\n",
    "It's also important to note that feature engineering can create new features with different scales and ranges, which can affect the performance of models that rely on distance-based calculations, such as KNN. In these cases, it's important to ensure that all features have the same scale and range, either by scaling each feature individually or by using a scaling method that takes into account the range of all features.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
