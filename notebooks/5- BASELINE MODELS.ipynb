{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0157c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from statistics import mean\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler #fixed import\n",
    "from sklearn import svm\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from langdetect import detect\n",
    "from scipy.sparse import hstack\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bfe7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ac276dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)  # Set random seed for numpy\n",
    "\n",
    "import random\n",
    "random.seed(42)  # Set random seed for random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f792bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\data\\\\data_processed_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b04bd387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #convert reason to numbers\n",
    "# reason_dict ={'Mau Serviço Prestado': 0, 'Condições de entrega': 1, 'Atraso de entrega': 2, \n",
    "#                'Enganos': 3}\n",
    "# df['reason'].replace(reason_dict, inplace=True)\n",
    "# df['reason'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1eb02a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df[['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4633757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15701, 5)\n",
      "y_train shape: (15701,)\n",
      "X_test shape: (6729, 5)\n",
      "y_test shape: (6729,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1815f",
   "metadata": {},
   "source": [
    "# 1. BOW WITH NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c7a48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyclf(X_train, y_train, vectorizer, model, feature_set):\n",
    "    X_train_selected = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "    \n",
    "    # Create a CountVectorizer and Multinomial Naive Bayes pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    # Define cross-validation strategy (e.g., StratifiedKFold with 5 folds)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store predictions and true labels\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    # Perform cross-validation and accumulate the confusion matrix\n",
    "    for train_index, val_index in kf.split(X_train_selected, y_train):\n",
    "        X_train_fold, X_val_fold = X_train_selected.iloc[train_index], X_train_selected.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Fit the model on the training fold\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the validation fold\n",
    "        y_pred_val = pipeline.predict(X_val_fold)\n",
    "        \n",
    "        # Append true labels and predicted labels\n",
    "        all_true_labels.extend(y_val_fold)\n",
    "        all_predicted_labels.extend(y_pred_val)\n",
    "        \n",
    "    # Get the number of features from the vectorizer\n",
    "    num_features = len(vectorizer.get_feature_names_out())\n",
    "    # Print the number of features, confusion matrix, and classification report\n",
    "    print(f\"Number of Features: {num_features}\")\n",
    "            \n",
    "    # Generate an overall confusion matrix\n",
    "    confusion_mat = confusion_matrix(all_true_labels, all_predicted_labels, labels=[0,1,2,3])\n",
    "    \n",
    "    # Calculate the classification report\n",
    "    class_report = classification_report(all_true_labels, all_predicted_labels, zero_division=1)\n",
    "\n",
    "    # Print the confusion matrix and classification report\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2b6e80ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 18785\n",
      "Confusion Matrix:\n",
      "[[3461  151 1901   63]\n",
      " [ 944  115  462   32]\n",
      " [1270   23 6187   30]\n",
      " [ 649   24  292   97]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      5576\n",
      "           1       0.37      0.07      0.12      1553\n",
      "           2       0.70      0.82      0.76      7510\n",
      "           3       0.44      0.09      0.15      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.51      0.40      0.40     15701\n",
      "weighted avg       0.59      0.63      0.59     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_tfidf']\n",
    "applyclf(X_train, y_train, CountVectorizer(), MultinomialNB(), feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05cd05b",
   "metadata": {},
   "source": [
    "# 2. TF-IDF WITH DIFFERENT ML MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc0b58",
   "metadata": {},
   "source": [
    "\"The choice of n-gram size for the title feature depends on the specific characteristics of your text data and the requirements of your classification task. However, since the title feature is typically shorter and more concise than the description feature, you might consider using a smaller n-gram range, such as unigrams (ngram_size=(1,1)) or bigrams (ngram_size=(2,2)), to capture the most important keywords or phrases in the title.\n",
    "\n",
    "Using a smaller n-gram range can help prevent overfitting and reduce the dimensionality of the feature space, while still capturing the key information in the title. However, it's also important to experiment with different n-gram ranges and compare their performance using cross-validation or hold-out validation to determine the most effective approach for your specific application.\n",
    "\n",
    "Additionally, you might also consider using different TF-IDF configurations for the title feature compared to the description feature, such as a different minimum document frequency threshold or weighting scheme, to better capture the unique characteristics of each feature type.\"  \n",
    "\n",
    "max_df=0.9 or 0.95 because the texts are short and have a similar structure,  \n",
    "min_df=1 or 2 just to keep rare words but remove typos, eg,  \n",
    "bigrams and trigrams because texts are short, using unigrams alone may not capture enough information?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e0754",
   "metadata": {},
   "source": [
    "### best tfidf configuration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b38a4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [KNeighborsClassifier(),\n",
    "               DecisionTreeClassifier(random_state=42), \n",
    "               RandomForestClassifier(random_state=42), \n",
    "               GradientBoostingClassifier(random_state=42),\n",
    "               XGBClassifier(random_state=42), \n",
    "               MultinomialNB(),\n",
    "               LinearSVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6eadbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration for KNeighborsClassifier:\n",
      "{'vectorizer__max_df': 0.7, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best F1-score: 0.3866297429328453\n",
      "\n",
      "Best Configuration for DecisionTreeClassifier:\n",
      "{'vectorizer__max_df': 0.7, 'vectorizer__min_df': 0.02, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best F1-score: 0.3565817113615028\n",
      "\n",
      "Best Configuration for RandomForestClassifier:\n",
      "{'vectorizer__max_df': 0.7, 'vectorizer__min_df': 0.02, 'vectorizer__ngram_range': (1, 3)}\n",
      "Best F1-score: 0.3562689961823028\n",
      "\n",
      "Best Configuration for GradientBoostingClassifier:\n",
      "{'vectorizer__max_df': 0.8, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best F1-score: 0.4095637717573499\n",
      "\n",
      "Best Configuration for XGBClassifier:\n",
      "{'vectorizer__max_df': 0.8, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best F1-score: 0.42781269338094674\n",
      "\n",
      "Best Configuration for MultinomialNB:\n",
      "{'vectorizer__max_df': 0.8, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 3)}\n",
      "Best F1-score: 0.3474747183792658\n",
      "\n",
      "Best Configuration for LinearSVC:\n",
      "{'vectorizer__max_df': 0.8, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 2)}\n",
      "Best F1-score: 0.4322460110479553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_selected = X_train[['narrative_tfidf']].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "# Create a parameter grid for TF-IDF configurations\n",
    "param_grid = {\n",
    "    'vectorizer__ngram_range': [(1, 2), (1, 3)],\n",
    "    'vectorizer__max_df': [0.7, 0.8, 0.9, 0.95],\n",
    "    'vectorizer__min_df': [0.01, 0.02, 0.03]\n",
    "}\n",
    "\n",
    "# Create an empty dictionary to store the best configurations and their scores for each classifier\n",
    "best_configs = {}\n",
    "\n",
    "# Loop through each classifier\n",
    "for clf in classifiers:\n",
    "    # Create a pipeline for the current classifier\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', TfidfVectorizer()),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "\n",
    "    # Perform grid search\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=kf, n_jobs=-1, scoring='f1_macro')\n",
    "    grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Get the best parameters and the associated accuracy\n",
    "    best_params = grid_search.best_params_\n",
    "    best_f1 = grid_search.best_score_\n",
    "\n",
    "    # Store the best configuration and accuracy for this classifier\n",
    "    best_configs[clf.__class__.__name__] = (best_params, best_f1)\n",
    "\n",
    "# Print the best configurations and their f1 for each classifier\n",
    "for clf_name, (best_params, best_f1) in best_configs.items():\n",
    "    print(f\"Best Configuration for {clf_name}:\")\n",
    "    print(best_params)\n",
    "    print(f\"Best F1-score: {best_f1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5790e3",
   "metadata": {},
   "source": [
    "best results is with linear svc and xgboost both with {'vectorizer__max_df': 0.8, 'vectorizer__min_df': 0.01, 'vectorizer__ngram_range': (1, 2)}, so I'm going to choose this config."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66466fc",
   "metadata": {},
   "source": [
    "## description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "885dba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3428    2 2137    9]\n",
      " [1003    0  547    3]\n",
      " [1080    1 6428    1]\n",
      " [ 662    0  376   24]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.58      5576\n",
      "           1       0.00      0.00      0.00      1553\n",
      "           2       0.68      0.86      0.76      7510\n",
      "           3       0.65      0.02      0.04      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.47      0.37      0.35     15701\n",
      "weighted avg       0.57      0.63      0.57     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3296  304 1835  141]\n",
      " [ 901  169  431   52]\n",
      " [1979  189 5286   56]\n",
      " [ 588   81  268  125]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.59      0.53      5576\n",
      "           1       0.23      0.11      0.15      1553\n",
      "           2       0.68      0.70      0.69      7510\n",
      "           3       0.33      0.12      0.17      1062\n",
      "\n",
      "    accuracy                           0.57     15701\n",
      "   macro avg       0.43      0.38      0.39     15701\n",
      "weighted avg       0.54      0.57      0.55     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[2628  601 1969  378]\n",
      " [ 680  214  530  129]\n",
      " [1964  456 4792  298]\n",
      " [ 442  136  323  161]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.47      5576\n",
      "           1       0.15      0.14      0.14      1553\n",
      "           2       0.63      0.64      0.63      7510\n",
      "           3       0.17      0.15      0.16      1062\n",
      "\n",
      "    accuracy                           0.50     15701\n",
      "   macro avg       0.35      0.35      0.35     15701\n",
      "weighted avg       0.49      0.50      0.49     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3459    2 2106    9]\n",
      " [ 978   10  560    5]\n",
      " [ 982    4 6520    4]\n",
      " [ 681    3  348   30]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.59      5576\n",
      "           1       0.53      0.01      0.01      1553\n",
      "           2       0.68      0.87      0.77      7510\n",
      "           3       0.62      0.03      0.05      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.60      0.38      0.36     15701\n",
      "weighted avg       0.62      0.64      0.58     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3419   71 1995   91]\n",
      " [ 964   60  489   40]\n",
      " [1090   15 6381   24]\n",
      " [ 591   18  305  148]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.61      0.59      5576\n",
      "           1       0.37      0.04      0.07      1553\n",
      "           2       0.70      0.85      0.77      7510\n",
      "           3       0.49      0.14      0.22      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.53      0.41      0.41     15701\n",
      "weighted avg       0.60      0.64      0.60     15701\n",
      "\n",
      "XGBClassifier\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3473  135 1865  103]\n",
      " [ 931  115  465   42]\n",
      " [1241   41 6196   32]\n",
      " [ 599   37  256  170]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59      5576\n",
      "           1       0.35      0.07      0.12      1553\n",
      "           2       0.71      0.83      0.76      7510\n",
      "           3       0.49      0.16      0.24      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.53      0.42      0.43     15701\n",
      "weighted avg       0.60      0.63      0.60     15701\n",
      "\n",
      "LinearSVC\n",
      "Number of Features: 1191\n",
      "Confusion Matrix:\n",
      "[[3343  173 1886  174]\n",
      " [ 877  108  485   83]\n",
      " [1170   50 6213   77]\n",
      " [ 514   57  267  224]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.60      0.58      5576\n",
      "           1       0.28      0.07      0.11      1553\n",
      "           2       0.70      0.83      0.76      7510\n",
      "           3       0.40      0.21      0.28      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.49      0.43      0.43     15701\n",
      "weighted avg       0.59      0.63      0.60     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_tfidf']\n",
    "config= {'ngram_range': (1,2), 'max_df':0.80, 'min_df': 0.01}\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf(X_train, y_train, TfidfVectorizer(**config), clf, feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede181c4",
   "metadata": {},
   "source": [
    "## description + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b0987be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3512    1 2043   20]\n",
      " [1028    0  515   10]\n",
      " [1040    2 6462    6]\n",
      " [ 678    0  321   63]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59      5576\n",
      "           1       0.00      0.00      0.00      1553\n",
      "           2       0.69      0.86      0.77      7510\n",
      "           3       0.64      0.06      0.11      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.47      0.39      0.37     15701\n",
      "weighted avg       0.57      0.64      0.58     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3308  293 1800  175]\n",
      " [ 902  189  414   48]\n",
      " [1773  186 5492   59]\n",
      " [ 579   80  222  181]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.59      0.55      5576\n",
      "           1       0.25      0.12      0.16      1553\n",
      "           2       0.69      0.73      0.71      7510\n",
      "           3       0.39      0.17      0.24      1062\n",
      "\n",
      "    accuracy                           0.58     15701\n",
      "   macro avg       0.46      0.40      0.41     15701\n",
      "weighted avg       0.56      0.58      0.57     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[2647  621 1900  408]\n",
      " [ 727  240  474  112]\n",
      " [1895  430 4943  242]\n",
      " [ 447  154  290  171]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.47      0.47      5576\n",
      "           1       0.17      0.15      0.16      1553\n",
      "           2       0.65      0.66      0.65      7510\n",
      "           3       0.18      0.16      0.17      1062\n",
      "\n",
      "    accuracy                           0.51     15701\n",
      "   macro avg       0.37      0.36      0.36     15701\n",
      "weighted avg       0.50      0.51      0.51     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3565    3 1976   32]\n",
      " [1010   11  522   10]\n",
      " [ 964    3 6531   12]\n",
      " [ 698    1  300   63]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60      5576\n",
      "           1       0.61      0.01      0.01      1553\n",
      "           2       0.70      0.87      0.78      7510\n",
      "           3       0.54      0.06      0.11      1062\n",
      "\n",
      "    accuracy                           0.65     15701\n",
      "   macro avg       0.61      0.39      0.38     15701\n",
      "weighted avg       0.63      0.65      0.59     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3511   77 1869  119]\n",
      " [ 960   74  464   55]\n",
      " [1075   19 6385   31]\n",
      " [ 593   10  263  196]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.63      0.60      5576\n",
      "           1       0.41      0.05      0.09      1553\n",
      "           2       0.71      0.85      0.77      7510\n",
      "           3       0.49      0.18      0.27      1062\n",
      "\n",
      "    accuracy                           0.65     15701\n",
      "   macro avg       0.55      0.43      0.43     15701\n",
      "weighted avg       0.62      0.65      0.61     15701\n",
      "\n",
      "XGBClassifier\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3554  130 1774  118]\n",
      " [ 955  110  427   61]\n",
      " [1195   52 6226   37]\n",
      " [ 588   35  219  220]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      5576\n",
      "           1       0.34      0.07      0.12      1553\n",
      "           2       0.72      0.83      0.77      7510\n",
      "           3       0.50      0.21      0.29      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.53      0.44      0.45     15701\n",
      "weighted avg       0.61      0.64      0.61     15701\n",
      "\n",
      "LinearSVC\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3394  180 1810  192]\n",
      " [ 882  126  459   86]\n",
      " [1157   53 6232   68]\n",
      " [ 507   56  244  255]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.61      0.59      5576\n",
      "           1       0.30      0.08      0.13      1553\n",
      "           2       0.71      0.83      0.77      7510\n",
      "           3       0.42      0.24      0.31      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.50      0.44      0.45     15701\n",
      "weighted avg       0.60      0.64      0.61     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_tfidf','tfidf_title']\n",
    "config= {'ngram_range': (1,2), 'max_df':0.80, 'min_df': 0.01}\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf(X_train, y_train, TfidfVectorizer(**config), clf, feature_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc2867",
   "metadata": {},
   "source": [
    "will other kernels perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90a222d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3744    8 1756   68]\n",
      " [1067   10  450   26]\n",
      " [1087    4 6401   18]\n",
      " [ 696    0  219  147]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62      5576\n",
      "           1       0.45      0.01      0.01      1553\n",
      "           2       0.73      0.85      0.78      7510\n",
      "           3       0.57      0.14      0.22      1062\n",
      "\n",
      "    accuracy                           0.66     15701\n",
      "   macro avg       0.58      0.42      0.41     15701\n",
      "weighted avg       0.63      0.66      0.61     15701\n",
      "\n",
      "SVC\n",
      "Number of Features: 1240\n",
      "Confusion Matrix:\n",
      "[[3478    8 2056   34]\n",
      " [ 999   16  526   12]\n",
      " [ 891    5 6607    7]\n",
      " [ 694    0  285   83]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.62      0.60      5576\n",
      "           1       0.55      0.01      0.02      1553\n",
      "           2       0.70      0.88      0.78      7510\n",
      "           3       0.61      0.08      0.14      1062\n",
      "\n",
      "    accuracy                           0.65     15701\n",
      "   macro avg       0.61      0.40      0.38     15701\n",
      "weighted avg       0.63      0.65      0.60     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_tfidf','tfidf_title']\n",
    "config= {'ngram_range': (1,2), 'max_df':0.80, 'min_df': 0.01}\n",
    "classifiers = [SVC(kernel='rbf'),SVC(kernel='poly')]\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf(X_train, y_train, TfidfVectorizer(**config), clf, feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f127945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63f1be63",
   "metadata": {},
   "source": [
    "# 3. EMBEDDINGS WITH DIFFERENT ML MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eda29c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df[['narrative_embeddings', 'embeddings_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19059ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15701, 2)\n",
      "y_train shape: (15701,)\n",
      "X_test shape: (6729, 2)\n",
      "y_test shape: (6729,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into a training set (70%) and a test set (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "106db254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_transformation(X, model):\n",
    "    '''returns the mean of the embeddings of the document'''\n",
    "    # initiating a sentence with all zeros\n",
    "    embedding_size = 600  \n",
    "    X_transformed = np.zeros((len(X), embedding_size))\n",
    "   \n",
    "    # Loop over each string in X\n",
    "    for i, sentence in enumerate(X):\n",
    "        # Loop over each word in the sentence and, if it is in the model's vocabulary, add its feature vector to the total\n",
    "        embeddings = [model[word] for word in sentence.split() if word in model]\n",
    "        if embeddings:\n",
    "            X_transformed[i] = np.mean(embeddings, axis=0)\n",
    "    return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5ff909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(MultinomialNB(), MultinomialNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8027a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyclf_emb(X_train, y_train, model, feature_set, emb_model):\n",
    "    X_train_selected = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "    # Transform the text data into embeddings\n",
    "    X_train_embeddings = embeddings_transformation(X_train_selected, emb_model)\n",
    "    \n",
    "    # Conditionally add MinMaxScaler if the model is MultinomialNB\n",
    "    if isinstance(model, MultinomialNB):\n",
    "        # Add MinMaxScaler before the classifier\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', MinMaxScaler()),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    \n",
    "    # Define cross-validation strategy (e.g., StratifiedKFold with 5 folds)\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Lists to store predictions and true labels\n",
    "    all_true_labels = []\n",
    "    all_predicted_labels = []\n",
    "\n",
    "    # Perform cross-validation and accumulate the confusion matrix\n",
    "    for train_index, val_index in kf.split(X_train_embeddings, y_train):\n",
    "        X_train_fold, X_val_fold = X_train_embeddings[train_index], X_train_embeddings[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        # Fit the model on the training fold\n",
    "        pipeline.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Predict on the validation fold\n",
    "        y_pred_val = pipeline.predict(X_val_fold)\n",
    "        \n",
    "        # Append true labels and predicted labels\n",
    "        all_true_labels.extend(y_val_fold)\n",
    "        all_predicted_labels.extend(y_pred_val)\n",
    "        \n",
    "    # Generate an overall confusion matrix\n",
    "    confusion_mat = confusion_matrix(all_true_labels, all_predicted_labels, labels=[0,1,2,3])\n",
    "    \n",
    "    # Calculate the classification report\n",
    "    class_report = classification_report(all_true_labels, all_predicted_labels, zero_division=1)\n",
    "\n",
    "    # Print the confusion matrix and classification report\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ab7a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(),\n",
    "               KNeighborsClassifier(),\n",
    "               DecisionTreeClassifier(random_state=42), \n",
    "               RandomForestClassifier(random_state=42), \n",
    "               GradientBoostingClassifier(random_state=42),\n",
    "               XGBClassifier(random_state=42),\n",
    "               LinearSVC()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ff884",
   "metadata": {},
   "source": [
    "## 3.1. WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "984a8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v= KeyedVectors.load_word2vec_format('D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\embeddings\\\\skip_s600_word2vec.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54324c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1880f26afa0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a918585d",
   "metadata": {},
   "source": [
    "## description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d7b66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Confusion Matrix:\n",
      "[[2814    0 2762    0]\n",
      " [ 856    0  697    0]\n",
      " [1123    0 6387    0]\n",
      " [ 543    0  519    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.52      5576\n",
      "           1       1.00      0.00      0.00      1553\n",
      "           2       0.62      0.85      0.71      7510\n",
      "           3       1.00      0.00      0.00      1062\n",
      "\n",
      "    accuracy                           0.59     15701\n",
      "   macro avg       0.79      0.34      0.31     15701\n",
      "weighted avg       0.65      0.59      0.52     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Confusion Matrix:\n",
      "[[4266  150 1087   73]\n",
      " [1193   59  268   33]\n",
      " [3755  159 3533   63]\n",
      " [ 818   42  138   64]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.77      0.55      5576\n",
      "           1       0.14      0.04      0.06      1553\n",
      "           2       0.70      0.47      0.56      7510\n",
      "           3       0.27      0.06      0.10      1062\n",
      "\n",
      "    accuracy                           0.50     15701\n",
      "   macro avg       0.39      0.33      0.32     15701\n",
      "weighted avg       0.52      0.50      0.48     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[2421  668 2047  440]\n",
      " [ 672  221  522  138]\n",
      " [2137  628 4352  393]\n",
      " [ 417  143  351  151]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43      5576\n",
      "           1       0.13      0.14      0.14      1553\n",
      "           2       0.60      0.58      0.59      7510\n",
      "           3       0.13      0.14      0.14      1062\n",
      "\n",
      "    accuracy                           0.46     15701\n",
      "   macro avg       0.32      0.32      0.32     15701\n",
      "weighted avg       0.46      0.46      0.46     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[3120   12 2440    4]\n",
      " [ 933    5  613    2]\n",
      " [1031    2 6476    1]\n",
      " [ 617    1  429   15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55      5576\n",
      "           1       0.25      0.00      0.01      1553\n",
      "           2       0.65      0.86      0.74      7510\n",
      "           3       0.68      0.01      0.03      1062\n",
      "\n",
      "    accuracy                           0.61     15701\n",
      "   macro avg       0.53      0.36      0.33     15701\n",
      "weighted avg       0.58      0.61      0.55     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Confusion Matrix:\n",
      "[[3454   71 1965   86]\n",
      " [ 967   55  469   62]\n",
      " [1228   37 6204   41]\n",
      " [ 626   18  283  135]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      5576\n",
      "           1       0.30      0.04      0.06      1553\n",
      "           2       0.70      0.83      0.76      7510\n",
      "           3       0.42      0.13      0.19      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.49      0.40      0.40     15701\n",
      "weighted avg       0.59      0.63      0.59     15701\n",
      "\n",
      "XGBClassifier\n",
      "Confusion Matrix:\n",
      "[[3448   91 1972   65]\n",
      " [ 938   75  498   42]\n",
      " [1229   27 6228   26]\n",
      " [ 609   33  321   99]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      5576\n",
      "           1       0.33      0.05      0.08      1553\n",
      "           2       0.69      0.83      0.75      7510\n",
      "           3       0.43      0.09      0.15      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.50      0.40      0.39     15701\n",
      "weighted avg       0.59      0.63      0.59     15701\n",
      "\n",
      "LinearSVC\n",
      "Confusion Matrix:\n",
      "[[3591   21 1912   52]\n",
      " [ 988   19  503   43]\n",
      " [1123   10 6362   15]\n",
      " [ 680    6  284   92]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      5576\n",
      "           1       0.34      0.01      0.02      1553\n",
      "           2       0.70      0.85      0.77      7510\n",
      "           3       0.46      0.09      0.15      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.51      0.40      0.38     15701\n",
      "weighted avg       0.60      0.64      0.59     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_embeddings']\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf_emb(X_train, y_train, clf, feature_set, w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16774cf",
   "metadata": {},
   "source": [
    "## description + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32cc96e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Confusion Matrix:\n",
      "[[2986    0 2589    1]\n",
      " [ 891    0  662    0]\n",
      " [1166    0 6344    0]\n",
      " [ 578    0  484    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.53      5576\n",
      "           1       1.00      0.00      0.00      1553\n",
      "           2       0.63      0.84      0.72      7510\n",
      "           3       0.00      0.00      0.00      1062\n",
      "\n",
      "    accuracy                           0.59     15701\n",
      "   macro avg       0.54      0.35      0.31     15701\n",
      "weighted avg       0.59      0.59      0.53     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Confusion Matrix:\n",
      "[[4237  141 1112   86]\n",
      " [1152   81  277   43]\n",
      " [3440  135 3864   71]\n",
      " [ 799   40  128   95]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.76      0.56      5576\n",
      "           1       0.20      0.05      0.08      1553\n",
      "           2       0.72      0.51      0.60      7510\n",
      "           3       0.32      0.09      0.14      1062\n",
      "\n",
      "    accuracy                           0.53     15701\n",
      "   macro avg       0.42      0.35      0.34     15701\n",
      "weighted avg       0.54      0.53      0.50     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[2486  648 1976  466]\n",
      " [ 640  241  524  148]\n",
      " [2070  584 4460  396]\n",
      " [ 416  173  323  150]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.44      5576\n",
      "           1       0.15      0.16      0.15      1553\n",
      "           2       0.61      0.59      0.60      7510\n",
      "           3       0.13      0.14      0.14      1062\n",
      "\n",
      "    accuracy                           0.47     15701\n",
      "   macro avg       0.33      0.33      0.33     15701\n",
      "weighted avg       0.47      0.47      0.47     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[3264    9 2300    3]\n",
      " [ 937    7  608    1]\n",
      " [1021    2 6487    0]\n",
      " [ 655    3  384   20]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.59      0.57      5576\n",
      "           1       0.33      0.00      0.01      1553\n",
      "           2       0.66      0.86      0.75      7510\n",
      "           3       0.83      0.02      0.04      1062\n",
      "\n",
      "    accuracy                           0.62     15701\n",
      "   macro avg       0.60      0.37      0.34     15701\n",
      "weighted avg       0.60      0.62      0.56     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Confusion Matrix:\n",
      "[[3550   66 1846  114]\n",
      " [ 973   56  465   59]\n",
      " [1183   27 6257   43]\n",
      " [ 609   30  247  176]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      5576\n",
      "           1       0.31      0.04      0.06      1553\n",
      "           2       0.71      0.83      0.77      7510\n",
      "           3       0.45      0.17      0.24      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.51      0.42      0.42     15701\n",
      "weighted avg       0.60      0.64      0.60     15701\n",
      "\n",
      "XGBClassifier\n",
      "Confusion Matrix:\n",
      "[[3557   98 1847   74]\n",
      " [ 952   80  475   46]\n",
      " [1183   29 6276   22]\n",
      " [ 621   28  267  146]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      5576\n",
      "           1       0.34      0.05      0.09      1553\n",
      "           2       0.71      0.84      0.77      7510\n",
      "           3       0.51      0.14      0.22      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.53      0.42      0.42     15701\n",
      "weighted avg       0.61      0.64      0.60     15701\n",
      "\n",
      "LinearSVC\n",
      "Confusion Matrix:\n",
      "[[3674   21 1803   78]\n",
      " [1005   27  472   49]\n",
      " [1099    8 6384   19]\n",
      " [ 664    4  258  136]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.66      0.61      5576\n",
      "           1       0.45      0.02      0.03      1553\n",
      "           2       0.72      0.85      0.78      7510\n",
      "           3       0.48      0.13      0.20      1062\n",
      "\n",
      "    accuracy                           0.65     15701\n",
      "   macro avg       0.55      0.41      0.41     15701\n",
      "weighted avg       0.62      0.65      0.61     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_embeddings', 'embeddings_title']\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf_emb(X_train, y_train, clf, feature_set, w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b511bd7",
   "metadata": {},
   "source": [
    "## 3.2 GLOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02b41038",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove= KeyedVectors.load_word2vec_format('D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\embeddings\\\\glove_s600.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6c616",
   "metadata": {},
   "source": [
    "## description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed19a1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Confusion Matrix:\n",
      "[[2791    0 2785    0]\n",
      " [ 857    0  696    0]\n",
      " [1277    0 6233    0]\n",
      " [ 546    0  516    0]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.50      0.51      5576\n",
      "           1       1.00      0.00      0.00      1553\n",
      "           2       0.61      0.83      0.70      7510\n",
      "           3       1.00      0.00      0.00      1062\n",
      "\n",
      "    accuracy                           0.57     15701\n",
      "   macro avg       0.78      0.33      0.30     15701\n",
      "weighted avg       0.64      0.57      0.52     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Confusion Matrix:\n",
      "[[4205  174 1116   81]\n",
      " [1179   72  268   34]\n",
      " [3795  162 3482   71]\n",
      " [ 780   43  169   70]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.75      0.54      5576\n",
      "           1       0.16      0.05      0.07      1553\n",
      "           2       0.69      0.46      0.56      7510\n",
      "           3       0.27      0.07      0.11      1062\n",
      "\n",
      "    accuracy                           0.50     15701\n",
      "   macro avg       0.39      0.33      0.32     15701\n",
      "weighted avg       0.52      0.50      0.47     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[2361  659 2122  434]\n",
      " [ 627  236  543  147]\n",
      " [2155  608 4310  437]\n",
      " [ 398  148  370  146]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.42      0.42      5576\n",
      "           1       0.14      0.15      0.15      1553\n",
      "           2       0.59      0.57      0.58      7510\n",
      "           3       0.13      0.14      0.13      1062\n",
      "\n",
      "    accuracy                           0.45     15701\n",
      "   macro avg       0.32      0.32      0.32     15701\n",
      "weighted avg       0.45      0.45      0.45     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[3098    6 2470    2]\n",
      " [ 899    8  644    2]\n",
      " [1056    4 6449    1]\n",
      " [ 598    5  444   15]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.56      0.55      5576\n",
      "           1       0.35      0.01      0.01      1553\n",
      "           2       0.64      0.86      0.74      7510\n",
      "           3       0.75      0.01      0.03      1062\n",
      "\n",
      "    accuracy                           0.61     15701\n",
      "   macro avg       0.57      0.36      0.33     15701\n",
      "weighted avg       0.59      0.61      0.55     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Confusion Matrix:\n",
      "[[3476   73 1954   73]\n",
      " [ 981   43  479   50]\n",
      " [1256   21 6205   28]\n",
      " [ 641   21  290  110]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58      5576\n",
      "           1       0.27      0.03      0.05      1553\n",
      "           2       0.70      0.83      0.75      7510\n",
      "           3       0.42      0.10      0.17      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.48      0.40      0.39     15701\n",
      "weighted avg       0.58      0.63      0.58     15701\n",
      "\n",
      "XGBClassifier\n",
      "Confusion Matrix:\n",
      "[[3483   72 1962   59]\n",
      " [ 939   54  519   41]\n",
      " [1258   25 6217   10]\n",
      " [ 635   23  300  104]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.59      5576\n",
      "           1       0.31      0.03      0.06      1553\n",
      "           2       0.69      0.83      0.75      7510\n",
      "           3       0.49      0.10      0.16      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.51      0.40      0.39     15701\n",
      "weighted avg       0.59      0.63      0.59     15701\n",
      "\n",
      "LinearSVC\n",
      "Confusion Matrix:\n",
      "[[3537   34 1917   88]\n",
      " [ 986   36  472   59]\n",
      " [1139   11 6336   24]\n",
      " [ 653   17  263  129]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59      5576\n",
      "           1       0.37      0.02      0.04      1553\n",
      "           2       0.70      0.84      0.77      7510\n",
      "           3       0.43      0.12      0.19      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.52      0.41      0.40     15701\n",
      "weighted avg       0.60      0.64      0.60     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_embeddings']\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf_emb(X_train, y_train, clf, feature_set, glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacdc1ce",
   "metadata": {},
   "source": [
    "## description + title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3404da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "Confusion Matrix:\n",
      "[[3003    0 2570    3]\n",
      " [ 893    0  660    0]\n",
      " [1330    0 6179    1]\n",
      " [ 589    0  471    2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.54      0.53      5576\n",
      "           1       1.00      0.00      0.00      1553\n",
      "           2       0.63      0.82      0.71      7510\n",
      "           3       0.33      0.00      0.00      1062\n",
      "\n",
      "    accuracy                           0.58     15701\n",
      "   macro avg       0.62      0.34      0.31     15701\n",
      "weighted avg       0.60      0.58      0.53     15701\n",
      "\n",
      "KNeighborsClassifier\n",
      "Confusion Matrix:\n",
      "[[4225  167 1107   77]\n",
      " [1159   79  274   41]\n",
      " [3552  152 3726   80]\n",
      " [ 770   61  155   76]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.76      0.55      5576\n",
      "           1       0.17      0.05      0.08      1553\n",
      "           2       0.71      0.50      0.58      7510\n",
      "           3       0.28      0.07      0.11      1062\n",
      "\n",
      "    accuracy                           0.52     15701\n",
      "   macro avg       0.40      0.34      0.33     15701\n",
      "weighted avg       0.53      0.52      0.49     15701\n",
      "\n",
      "DecisionTreeClassifier\n",
      "Confusion Matrix:\n",
      "[[2406  632 2081  457]\n",
      " [ 671  212  518  152]\n",
      " [2076  626 4405  403]\n",
      " [ 430  152  349  131]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.43      0.43      5576\n",
      "           1       0.13      0.14      0.13      1553\n",
      "           2       0.60      0.59      0.59      7510\n",
      "           3       0.11      0.12      0.12      1062\n",
      "\n",
      "    accuracy                           0.46     15701\n",
      "   macro avg       0.32      0.32      0.32     15701\n",
      "weighted avg       0.46      0.46      0.46     15701\n",
      "\n",
      "RandomForestClassifier\n",
      "Confusion Matrix:\n",
      "[[3170    4 2399    3]\n",
      " [ 902   10  638    3]\n",
      " [1056    2 6451    1]\n",
      " [ 611    1  425   25]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.57      0.56      5576\n",
      "           1       0.59      0.01      0.01      1553\n",
      "           2       0.65      0.86      0.74      7510\n",
      "           3       0.78      0.02      0.05      1062\n",
      "\n",
      "    accuracy                           0.61     15701\n",
      "   macro avg       0.64      0.36      0.34     15701\n",
      "weighted avg       0.62      0.61      0.56     15701\n",
      "\n",
      "GradientBoostingClassifier\n",
      "Confusion Matrix:\n",
      "[[3533   59 1906   78]\n",
      " [ 973   59  462   59]\n",
      " [1224   25 6234   27]\n",
      " [ 634   27  266  135]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.63      0.59      5576\n",
      "           1       0.35      0.04      0.07      1553\n",
      "           2       0.70      0.83      0.76      7510\n",
      "           3       0.45      0.13      0.20      1062\n",
      "\n",
      "    accuracy                           0.63     15701\n",
      "   macro avg       0.51      0.41      0.40     15701\n",
      "weighted avg       0.60      0.63      0.59     15701\n",
      "\n",
      "XGBClassifier\n",
      "Confusion Matrix:\n",
      "[[3578   77 1862   59]\n",
      " [ 965   65  479   44]\n",
      " [1232   29 6228   21]\n",
      " [ 659   30  256  117]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60      5576\n",
      "           1       0.32      0.04      0.07      1553\n",
      "           2       0.71      0.83      0.76      7510\n",
      "           3       0.49      0.11      0.18      1062\n",
      "\n",
      "    accuracy                           0.64     15701\n",
      "   macro avg       0.52      0.41      0.40     15701\n",
      "weighted avg       0.60      0.64      0.60     15701\n",
      "\n",
      "LinearSVC\n",
      "Confusion Matrix:\n",
      "[[3647   36 1792  101]\n",
      " [ 976   49  462   66]\n",
      " [1119   13 6352   26]\n",
      " [ 642   11  231  178]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.65      0.61      5576\n",
      "           1       0.45      0.03      0.06      1553\n",
      "           2       0.72      0.85      0.78      7510\n",
      "           3       0.48      0.17      0.25      1062\n",
      "\n",
      "    accuracy                           0.65     15701\n",
      "   macro avg       0.55      0.42      0.42     15701\n",
      "weighted avg       0.62      0.65      0.61     15701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_set=['narrative_embeddings', 'embeddings_title']\n",
    "for clf in classifiers:\n",
    "    print(clf.__class__.__name__)\n",
    "    applyclf_emb(X_train, y_train, clf, feature_set, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0dc6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0dd85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
