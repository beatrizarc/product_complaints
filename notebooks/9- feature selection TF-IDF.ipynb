{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7f69ac",
   "metadata": {},
   "source": [
    "* do feature scalling and selection to see if it improves and converges \n",
    "* perform feature scaling before feature selection  \n",
    "\n",
    "https://desirabletomorrows.org/assets/files/GARCIA-A.C.etal.FeatureSelectionMethodsforTextClassification.pdf  \n",
    "https://www.analyticsvidhya.com/blog/2020/10/feature-selection-techniques-in-machine-learning/\n",
    "\n",
    "Feature Selection Techniques: \n",
    "1. Filter Methods:\n",
    "   - Chi-square test: This method assesses the independence between categorical features and a categorical target variable. It is suitable for categorical variables and a categorical target.\n",
    "   - Information gain: It measures the reduction in entropy or disorder of the target variable based on each feature. It is suitable for categorical or numerical features and a categorical target.  \n",
    "   - Fisher score\n",
    "\n",
    "2. Wrapper Methods: Wrapper methods can be computationally expensive, especially if the feature space is large\n",
    "   - Recursive Feature Elimination (RFE): It recursively eliminates features and builds models based on the remaining features. It assesses the model's performance at each step to determine feature relevance. It can be used with any type of features and any type of target.\n",
    "   - Forward/Backward Stepwise Selection: These methods iteratively add or remove features based on their individual performance in the model. They can be used with any type of features and any type of target.\n",
    "\n",
    "3. Embedded Methods:\n",
    "   - LASSO (Least Absolute Shrinkage and Selection Operator): It applies L1 regularization to linear regression models, promoting sparsity in the coefficient estimates. It is suitable for numerical features and a numerical target.\n",
    "   - Ridge Regression: It applies L2 regularization to linear regression models, which can shrink less important features towards zero. It is suitable for numerical features and a numerical target.\n",
    "   - Elastic Net: It combines L1 and L2 regularization methods to balance between feature selection and regularization. It is suitable for numerical features and a numerical target.\n",
    "   - Regularized Tree-Based Methods: These include techniques like Random Forests with feature importance ranking and tree-based regularization techniques like XGBoost and LightGBM. They can handle different types of features and targets.\n",
    "\n",
    "5. Univariate Selection:\n",
    "   - ANOVA F-test: It measures the dependence between numerical features and a categorical target. It is suitable for numerical features and a categorical target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a865d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from nltk import word_tokenize\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel \n",
    "from scipy.stats import randint\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.feature_selection import RFECV, RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b29c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)  # Set random seed for numpy\n",
    "\n",
    "import random\n",
    "random.seed(42)  # Set random seed for random module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18fd930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\MS DATA SCIENCE\\\\NLP TESE\\\\data\\\\data_processed_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "810ba137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_entities(row):\n",
    "    if pd.isna(row)==False:\n",
    "        entities = row.lower()  # Convert to lowercase\n",
    "        entities = entities.replace(',', '')  # Remove commas\n",
    "        entities = ' '.join(set(entities.split()))  # Convert to set to get unique values, then join back as a string\n",
    "        return entities\n",
    "df['entities'] = df['entities'].apply(preprocess_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8db06b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "features = ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf', 'entities']\n",
    "feature_combinations = []\n",
    "\n",
    "# Generate the power set of features\n",
    "for r in range(1, len(features) + 1):\n",
    "    combinations = itertools.combinations(features, r)\n",
    "    feature_combinations.extend(combinations)\n",
    "\n",
    "# Convert each feature combination to a list\n",
    "feature_combinations = [list(combination) for combination in feature_combinations]\n",
    "print(len(feature_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5c5690",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_combinations = []\n",
    "\n",
    "for t in feature_combinations:\n",
    "    if not df[t].isna().all(axis=1).any():\n",
    "        new_feature_combinations.append(t)\n",
    "\n",
    "feature_combinations = [feature_comb for feature_comb in new_feature_combinations if 'narrative_tfidf' in feature_comb and 'tfidf_title' in feature_comb]\n",
    "feature_combinations.append(['narrative_tfidf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f4e8172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['narrative_tfidf', 'tfidf_title'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'events_tfidf'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'entities'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'entities'],\n",
       " ['narrative_tfidf', 'tfidf_title', 'events_tfidf', 'entities'],\n",
       " ['narrative_tfidf',\n",
       "  'tfidf_title',\n",
       "  'tfidf_keywords',\n",
       "  'events_tfidf',\n",
       "  'entities'],\n",
       " ['narrative_tfidf']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d7caf",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96fc2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['reason']\n",
    "X = df[['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf', 'entities']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "581af8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15701, 5)\n",
      "y_train shape: (15701,)\n",
      "X_val shape: (3364, 5)\n",
      "y_val shape: (3364,)\n",
      "X_test shape: (3365, 5)\n",
      "y_test shape: (3365,)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Split the remaining data into validation and test sets\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, stratify=y_test, random_state=42)\n",
    "\n",
    "# Print the shape of each set\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e0ab6",
   "metadata": {},
   "source": [
    "### does scaling help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f3d0969",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 33.2 GiB for an array with shape (15701, 284224) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_train_combined_transformed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodense\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\scipy\\sparse\\_base.py:946\u001b[0m, in \u001b[0;36mspmatrix.todense\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtodense\u001b[39m(\u001b[38;5;28mself\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    917\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;124;03m    Return a dense matrix representation of this matrix.\u001b[39;00m\n\u001b[0;32m    919\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;124;03m        `numpy.matrix` object that shares the same memory.\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 946\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ascontainer(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\scipy\\sparse\\_compressed.py:1051\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1050\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1051\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\scipy\\sparse\\_base.py:1298\u001b[0m, in \u001b[0;36mspmatrix._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 33.2 GiB for an array with shape (15701, 284224) and data type float64"
     ]
    }
   ],
   "source": [
    "X_train_combined_transformed.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd0a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(feature_combinations, X_train, X_val, scaler,algorithm, y_train, y_val):\n",
    "    # Initialize the results table\n",
    "    cont=0\n",
    "\n",
    "    # Initialize an empty list to store individual result DataFrames\n",
    "    result_dfs = []\n",
    "    # Initialize the results table\n",
    "    results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                    'F1-Score', 'Nr feature before'])\n",
    "\n",
    "    # Evaluate models for each feature combination and algorithm\n",
    "    for feature_set in feature_combinations:\n",
    "        cont += 1\n",
    "        X_train_combined = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "        X_val_combined = X_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "        # Transform the features using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "        X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "        X_val_combined_transformed = vectorizer.transform(X_val_combined)\n",
    "\n",
    "        # Nr features before\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        num_features_before = len(feature_names)\n",
    "\n",
    "        # Feature scaling\n",
    "        # scaler = MaxAbsScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train_combined_transformed)\n",
    "        X_val_scaled = scaler.transform(X_val_combined_transformed)\n",
    "\n",
    "        # Train the model\n",
    "        # algorithm= LinearSVC(max_iter=2000)\n",
    "        algorithm.fit(X_train_scaled, y_train)\n",
    "\n",
    "        # Predict labels\n",
    "        y_pred = algorithm.predict(X_val_scaled)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred, average='macro')\n",
    "        recall = recall_score(y_val, y_pred, average='macro')\n",
    "        f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "        # Create a DataFrame for the current combination and algorithm\n",
    "        result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                  'Accuracy': [accuracy],\n",
    "                                  'Precision': [precision],\n",
    "                                  'Recall': [recall],\n",
    "                                  'F1-Score': [f1],\n",
    "                                  'Nr feature before':[num_features_before]})\n",
    "        # Append the DataFrame to the list\n",
    "        result_dfs.append(result_df)\n",
    "\n",
    "        print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "    # Concatenate all the result DataFrames into a single DataFrame\n",
    "    results_scaling = pd.concat(result_dfs, ignore_index=True)\n",
    "    return results_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f3d668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.646254</td>\n",
       "      <td>0.509206</td>\n",
       "      <td>0.456454</td>\n",
       "      <td>0.467845</td>\n",
       "      <td>211325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.647741</td>\n",
       "      <td>0.515034</td>\n",
       "      <td>0.449445</td>\n",
       "      <td>0.461037</td>\n",
       "      <td>239686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.642390</td>\n",
       "      <td>0.507407</td>\n",
       "      <td>0.448946</td>\n",
       "      <td>0.460072</td>\n",
       "      <td>256564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.641201</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.454708</td>\n",
       "      <td>0.467698</td>\n",
       "      <td>217451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.646254</td>\n",
       "      <td>0.514554</td>\n",
       "      <td>0.446398</td>\n",
       "      <td>0.457357</td>\n",
       "      <td>284224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.645065</td>\n",
       "      <td>0.507805</td>\n",
       "      <td>0.444778</td>\n",
       "      <td>0.455548</td>\n",
       "      <td>245458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.642985</td>\n",
       "      <td>0.503758</td>\n",
       "      <td>0.448418</td>\n",
       "      <td>0.458734</td>\n",
       "      <td>262304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.648335</td>\n",
       "      <td>0.514317</td>\n",
       "      <td>0.445482</td>\n",
       "      <td>0.455827</td>\n",
       "      <td>289922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.633175</td>\n",
       "      <td>0.498001</td>\n",
       "      <td>0.441432</td>\n",
       "      <td>0.452450</td>\n",
       "      <td>203837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.646254   0.509206   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.647741   0.515034   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.642390   0.507407   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.641201   0.511699   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.646254   0.514554   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.645065   0.507805   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.642985   0.503758   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.648335   0.514317   \n",
       "8                                    narrative_tfidf  0.633175   0.498001   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  \n",
       "0  0.456454  0.467845             211325  \n",
       "1  0.449445  0.461037             239686  \n",
       "2  0.448946  0.460072             256564  \n",
       "3  0.454708  0.467698             217451  \n",
       "4  0.446398  0.457357             284224  \n",
       "5  0.444778  0.455548             245458  \n",
       "6  0.448418  0.458734             262304  \n",
       "7  0.445482  0.455827             289922  \n",
       "8  0.441432  0.452450             203837  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scaling=scaling(feature_combinations, X_train, X_val, MaxAbsScaler(),LinearSVC(max_iter=3000), y_train, y_val)\n",
    "results_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93659f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.546550</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.462223</td>\n",
       "      <td>211325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>0.559104</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.467326</td>\n",
       "      <td>239686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.662901</td>\n",
       "      <td>0.550561</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.465398</td>\n",
       "      <td>256564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.657253</td>\n",
       "      <td>0.545262</td>\n",
       "      <td>0.453359</td>\n",
       "      <td>0.463684</td>\n",
       "      <td>217451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.554039</td>\n",
       "      <td>0.453728</td>\n",
       "      <td>0.465004</td>\n",
       "      <td>284224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.512385</td>\n",
       "      <td>0.434590</td>\n",
       "      <td>0.440465</td>\n",
       "      <td>245458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.658442</td>\n",
       "      <td>0.537404</td>\n",
       "      <td>0.449618</td>\n",
       "      <td>0.456914</td>\n",
       "      <td>262304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.662307</td>\n",
       "      <td>0.558208</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>289922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.645957</td>\n",
       "      <td>0.518850</td>\n",
       "      <td>0.430046</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>203837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.659334   0.546550   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.664090   0.559104   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.662901   0.550561   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.657253   0.545262   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.659631   0.554039   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.651605   0.512385   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.658442   0.537404   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.662307   0.558208   \n",
       "8                                    narrative_tfidf  0.645957   0.518850   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  \n",
       "0  0.451500  0.462223             211325  \n",
       "1  0.456817  0.467326             239686  \n",
       "2  0.455170  0.465398             256564  \n",
       "3  0.453359  0.463684             217451  \n",
       "4  0.453728  0.465004             284224  \n",
       "5  0.434590  0.440465             245458  \n",
       "6  0.449618  0.456914             262304  \n",
       "7  0.460919  0.474053             289922  \n",
       "8  0.430046  0.435547             203837  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scaling=scaling(feature_combinations, X_train, X_val, MaxAbsScaler(),XGBClassifier(), y_train, y_val)\n",
    "results_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ed02db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 2 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 3 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 4 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 5 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 6 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 7 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 8 of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.634661</td>\n",
       "      <td>0.525675</td>\n",
       "      <td>0.419825</td>\n",
       "      <td>0.428227</td>\n",
       "      <td>211325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.631094</td>\n",
       "      <td>0.495797</td>\n",
       "      <td>0.408067</td>\n",
       "      <td>0.410422</td>\n",
       "      <td>239686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.632878</td>\n",
       "      <td>0.509908</td>\n",
       "      <td>0.411542</td>\n",
       "      <td>0.416124</td>\n",
       "      <td>256564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.632580</td>\n",
       "      <td>0.532252</td>\n",
       "      <td>0.417684</td>\n",
       "      <td>0.426176</td>\n",
       "      <td>217408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.630797</td>\n",
       "      <td>0.482126</td>\n",
       "      <td>0.399745</td>\n",
       "      <td>0.396878</td>\n",
       "      <td>284224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.632878</td>\n",
       "      <td>0.499109</td>\n",
       "      <td>0.407107</td>\n",
       "      <td>0.408500</td>\n",
       "      <td>245489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.638228</td>\n",
       "      <td>0.523875</td>\n",
       "      <td>0.419148</td>\n",
       "      <td>0.426173</td>\n",
       "      <td>262484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.634958</td>\n",
       "      <td>0.487328</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.401779</td>\n",
       "      <td>290111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.627527</td>\n",
       "      <td>0.493628</td>\n",
       "      <td>0.406825</td>\n",
       "      <td>0.409671</td>\n",
       "      <td>203837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.634661   0.525675   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.631094   0.495797   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.632878   0.509908   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.632580   0.532252   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.630797   0.482126   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.632878   0.499109   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.638228   0.523875   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.634958   0.487328   \n",
       "8                                    narrative_tfidf  0.627527   0.493628   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  \n",
       "0  0.419825  0.428227             211325  \n",
       "1  0.408067  0.410422             239686  \n",
       "2  0.411542  0.416124             256564  \n",
       "3  0.417684  0.426176             217408  \n",
       "4  0.399745  0.396878             284224  \n",
       "5  0.407107  0.408500             245489  \n",
       "6  0.419148  0.426173             262484  \n",
       "7  0.403677  0.401779             290111  \n",
       "8  0.406825  0.409671             203837  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scaling=scaling(feature_combinations, X_train, X_val, StandardScaler(with_mean=False),LinearSVC(max_iter=5500), y_train, y_val)\n",
    "results_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8e28fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.546550</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.462223</td>\n",
       "      <td>211325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>0.559104</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.467326</td>\n",
       "      <td>239686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.662901</td>\n",
       "      <td>0.550561</td>\n",
       "      <td>0.455170</td>\n",
       "      <td>0.465398</td>\n",
       "      <td>256564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.657253</td>\n",
       "      <td>0.545262</td>\n",
       "      <td>0.453359</td>\n",
       "      <td>0.463684</td>\n",
       "      <td>217451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.554039</td>\n",
       "      <td>0.453728</td>\n",
       "      <td>0.465004</td>\n",
       "      <td>284224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.512385</td>\n",
       "      <td>0.434590</td>\n",
       "      <td>0.440465</td>\n",
       "      <td>245458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.658442</td>\n",
       "      <td>0.537404</td>\n",
       "      <td>0.449618</td>\n",
       "      <td>0.456914</td>\n",
       "      <td>262304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.662307</td>\n",
       "      <td>0.558208</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>289922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.645957</td>\n",
       "      <td>0.518850</td>\n",
       "      <td>0.430046</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>203837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.659334   0.546550   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.664090   0.559104   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.662901   0.550561   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.657253   0.545262   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.659631   0.554039   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.651605   0.512385   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.658442   0.537404   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.662307   0.558208   \n",
       "8                                    narrative_tfidf  0.645957   0.518850   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  \n",
       "0  0.451500  0.462223             211325  \n",
       "1  0.456817  0.467326             239686  \n",
       "2  0.455170  0.465398             256564  \n",
       "3  0.453359  0.463684             217451  \n",
       "4  0.453728  0.465004             284224  \n",
       "5  0.434590  0.440465             245458  \n",
       "6  0.449618  0.456914             262304  \n",
       "7  0.460919  0.474053             289922  \n",
       "8  0.430046  0.435547             203837  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scaling=scaling(feature_combinations, X_train, X_val, StandardScaler(with_mean=False),XGBClassifier(), y_train, y_val)\n",
    "results_scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6fc73d",
   "metadata": {},
   "source": [
    "Does not help, probably because TF-IDF encoding already incorporates a form of normalization within its calculation (TF); sparse matrices with lots of zeros; we need relative importance of terms within the TF-IDF vectors and scalling can disrupte them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456ee7a0",
   "metadata": {},
   "source": [
    "### chi-square (c/ stratified 6fold cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4467e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = pd.concat([X_train, X_val], axis=0, ignore_index=True)\n",
    "y_train_val = pd.concat([y_train, y_val], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3144fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_k(X_train_val, model, feature_set):\n",
    "    best_k = None\n",
    "    best_score = 0\n",
    "\n",
    "    X_train_val_combined = X_train_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "    X_train_val_combined_transformed = vectorizer.fit_transform(X_train_val_combined)\n",
    "    \n",
    "    # Perform a grid search over 'k' values and select the best 'k'\n",
    "    for k in range(1000,21001,1000):\n",
    "        selector = SelectKBest(chi2, k=k)\n",
    "        X_new = selector.fit_transform(X_train_val_combined_transformed, y_train_val)\n",
    "\n",
    "        # Train the model and evaluate with cross-validation\n",
    "        cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "        scores = cross_val_score(model, X_new, y_train_val, cv=cv, scoring='f1_macro')\n",
    "        mean_score = np.mean(scores)\n",
    "\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "\n",
    "    print('Best k for feature_set {} is: {}'.format(feature_set,best_k)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae0c3c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title'] is: 12000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords'] is: 9000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'events_tfidf'] is: 14000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'entities'] is: 14000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf'] is: 10000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'entities'] is: 12000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'events_tfidf', 'entities'] is: 14000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords', 'events_tfidf', 'entities'] is: 12000\n",
      "Best k for feature_set ['narrative_tfidf'] is: 19000\n"
     ]
    }
   ],
   "source": [
    "for feature_set in feature_combinations:\n",
    "    best_k(X_train_val, LinearSVC(), feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b14f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_linearsvc=[1200,9000,14000,14000,10000,12000,14000,12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "803d4265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title'] is: 3000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'tfidf_keywords'] is: 4000\n",
      "Best k for feature_set ['narrative_tfidf', 'tfidf_title', 'events_tfidf'] is: 9000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feature_set \u001b[38;5;129;01min\u001b[39;00m feature_combinations:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mbest_k\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXGBClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m, in \u001b[0;36mbest_k\u001b[1;34m(X_train_val, model, feature_set)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Train the model and evaluate with cross-validation\u001b[39;00m\n\u001b[0;32m     15\u001b[0m cv \u001b[38;5;241m=\u001b[39m StratifiedKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1_macro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m mean_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(scores)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean_score \u001b[38;5;241m>\u001b[39m best_score:\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1462\u001b[0m (\n\u001b[0;32m   1463\u001b[0m     model,\n\u001b[0;32m   1464\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1469\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1470\u001b[0m )\n\u001b[0;32m   1471\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1472\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1473\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1488\u001b[0m )\n\u001b[1;32m-> 1490\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\ms data science\\nlp tese\\envs\\env1\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for feature_set in feature_combinations:\n",
    "    best_k(X_train_val, XGBClassifier(), feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65bb264",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k_xgboost= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866ae8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_feature_selection_cv(feature_combinations, X_train_val, y_train_val, model, best_k):\n",
    "    # Initialize the results table\n",
    "    cont=0\n",
    "\n",
    "    # Initialize an empty list to store individual result DataFrames\n",
    "    result_dfs = []\n",
    "    # Initialize the results table\n",
    "    results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                    'F1-Score', 'Nr feature before', 'Nr features after'])\n",
    "\n",
    "    # Evaluate models for each feature combination and algorithm\n",
    "    for feature_set in feature_combinations:\n",
    "        cont += 1\n",
    "        X_train_combined = X_train_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "        # Transform the features using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "        X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "\n",
    "        # Nr features before\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        num_features_before = len(feature_names)\n",
    "\n",
    "        selector = SelectKBest(score_func=chi2, k=best_k[cont-1])\n",
    "        X_train_selected = selector.fit_transform(X_train_combined_transformed, y_train_val)\n",
    "\n",
    "        # Train the model and evaluate with cross-validation\n",
    "        cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "        f1_scores = cross_val_score(model, X_train_selected, y_train_val, cv=cv, scoring='f1_macro')\n",
    "        acc_scores = cross_val_score(model, X_train_selected, y_train_val, cv=cv, scoring='accuracy')\n",
    "        rec_scores = cross_val_score(model, X_train_selected, y_train_val, cv=cv, scoring='recall_macro')\n",
    "        prec_scores = cross_val_score(model, X_train_selected, y_train_val, cv=cv, scoring='precision_macro')\n",
    "\n",
    "        # Calculate Mean Cross-validation scores\n",
    "        accuracy = acc_scores.mean()\n",
    "        precision = prec_scores.mean()\n",
    "        recall = rec_scores.mean()\n",
    "        f1 = f1_scores.mean()\n",
    "        \n",
    "        # Create a DataFrame for the current combination and algorithm\n",
    "        result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                  'Accuracy': [accuracy],\n",
    "                                  'Precision': [precision],\n",
    "                                  'Recall': [recall],\n",
    "                                  'F1-Score': [f1],\n",
    "                                  'Nr feature before':[num_features_before], \n",
    "                                  'Nr features after':[best_k[cont-1]]})\n",
    "        # Append the DataFrame to the list\n",
    "        result_dfs.append(result_df)\n",
    "\n",
    "        print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "    # Concatenate all the result DataFrames into a single DataFrame\n",
    "    results = pd.concat(result_dfs, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b950b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= chi2_feature_selection_cv(feature_combinations, X_train_val, y_train_val, LinearSVC(), best_k_linearsvc)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= chi2_feature_selection_cv(feature_combinations, X_train_val, y_train_val, XGBClassifier(), best_k_xgboost)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8b669",
   "metadata": {},
   "source": [
    "### chi2 (with holdout cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "645356cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(X_train, X_val, y_train, y_val, n, classifier):\n",
    "    #same as selector.fit(X_train, y_train) and then X_train_selected = selector.transform(X_train)\n",
    "    selector = SelectKBest(score_func=chi2, k=n)\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "    \n",
    "    # Train the model\n",
    "    classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Predict labels\n",
    "    y_pred = classifier.predict(X_val_selected)\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred, average='macro')\n",
    "    recall = recall_score(y_val, y_pred, average='macro')\n",
    "    f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4636bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, classifier, low, high, step):\n",
    "    # Initialize the results table\n",
    "    cont=0\n",
    "\n",
    "    # Initialize an empty list to store individual result DataFrames\n",
    "    result_dfs = []\n",
    "    # Initialize the results table\n",
    "    results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                    'F1-Score', 'Nr feature before', 'Nr features after'])\n",
    "\n",
    "    # Evaluate models for each feature combination and algorithm\n",
    "    for feature_set in feature_combinations:\n",
    "        cont += 1\n",
    "        X_train_combined = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "        X_val_combined = X_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "        # Transform the features using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "        X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "        X_val_combined_transformed = vectorizer.transform(X_val_combined)\n",
    "\n",
    "        # Nr features before\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        num_features_before = len(feature_names)\n",
    "\n",
    "        max_f1=0\n",
    "        maxs=(0,0,0,0)\n",
    "        best_num_features=0\n",
    "        for i in range(low, high, step):\n",
    "            accuracy, precision, recall, f1= chi_square(X_train_combined_transformed, X_val_combined_transformed,\n",
    "                                                        y_train, y_val, i, classifier)\n",
    "            if f1>max_f1:\n",
    "                max_f1=f1\n",
    "                maxs=(accuracy, precision, recall, f1)\n",
    "                best_num_features=i\n",
    "\n",
    "        # Create a DataFrame for the current combination and algorithm\n",
    "        accuracy, precision, recall, f1= maxs\n",
    "        result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                  'Accuracy': [accuracy],\n",
    "                                  'Precision': [precision],\n",
    "                                  'Recall': [recall],\n",
    "                                  'F1-Score': [f1],\n",
    "                                  'Nr feature before':[num_features_before], \n",
    "                                  'Nr features after':[best_num_features]})\n",
    "        # Append the DataFrame to the list\n",
    "        result_dfs.append(result_df)\n",
    "\n",
    "        print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "    # Concatenate all the result DataFrames into a single DataFrame\n",
    "    results = pd.concat(result_dfs, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b86bea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.662901</td>\n",
       "      <td>0.546918</td>\n",
       "      <td>0.448868</td>\n",
       "      <td>0.457685</td>\n",
       "      <td>211325</td>\n",
       "      <td>17000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.664982</td>\n",
       "      <td>0.564262</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>0.454169</td>\n",
       "      <td>239686</td>\n",
       "      <td>9000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.657551</td>\n",
       "      <td>0.533553</td>\n",
       "      <td>0.436077</td>\n",
       "      <td>0.442641</td>\n",
       "      <td>256564</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.668847</td>\n",
       "      <td>0.553064</td>\n",
       "      <td>0.453194</td>\n",
       "      <td>0.461752</td>\n",
       "      <td>217451</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.549572</td>\n",
       "      <td>0.440608</td>\n",
       "      <td>0.448948</td>\n",
       "      <td>284224</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.662307</td>\n",
       "      <td>0.554895</td>\n",
       "      <td>0.441991</td>\n",
       "      <td>0.449947</td>\n",
       "      <td>245458</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.657551</td>\n",
       "      <td>0.525003</td>\n",
       "      <td>0.435993</td>\n",
       "      <td>0.441559</td>\n",
       "      <td>262304</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.656361</td>\n",
       "      <td>0.549502</td>\n",
       "      <td>0.440020</td>\n",
       "      <td>0.448698</td>\n",
       "      <td>289922</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.662010</td>\n",
       "      <td>0.548735</td>\n",
       "      <td>0.436944</td>\n",
       "      <td>0.441998</td>\n",
       "      <td>203837</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.662901   0.546918   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.664982   0.564262   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.657551   0.533553   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.668847   0.553064   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.657848   0.549572   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.662307   0.554895   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.657551   0.525003   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.656361   0.549502   \n",
       "8                                    narrative_tfidf  0.662010   0.548735   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0  0.448868  0.457685             211325              17000  \n",
       "1  0.444714  0.454169             239686               9000  \n",
       "2  0.436077  0.442641             256564              18000  \n",
       "3  0.453194  0.461752             217451              10000  \n",
       "4  0.440608  0.448948             284224              18000  \n",
       "5  0.441991  0.449947             245458               8000  \n",
       "6  0.435993  0.441559             262304              19000  \n",
       "7  0.440020  0.448698             289922              18000  \n",
       "8  0.436944  0.441998             203837               6000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=chi2_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, LinearSVC(), low=1000, high=21001, step=1000)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c79099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.664388</td>\n",
       "      <td>0.550169</td>\n",
       "      <td>0.450645</td>\n",
       "      <td>0.459736</td>\n",
       "      <td>211325</td>\n",
       "      <td>17200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.663496</td>\n",
       "      <td>0.567776</td>\n",
       "      <td>0.444587</td>\n",
       "      <td>0.454427</td>\n",
       "      <td>239686</td>\n",
       "      <td>7700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>0.535086</td>\n",
       "      <td>0.436441</td>\n",
       "      <td>0.443019</td>\n",
       "      <td>256564</td>\n",
       "      <td>18200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.667063</td>\n",
       "      <td>0.555337</td>\n",
       "      <td>0.454075</td>\n",
       "      <td>0.464349</td>\n",
       "      <td>217451</td>\n",
       "      <td>10600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.548460</td>\n",
       "      <td>0.441998</td>\n",
       "      <td>0.450269</td>\n",
       "      <td>284224</td>\n",
       "      <td>18700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.664388</td>\n",
       "      <td>0.561472</td>\n",
       "      <td>0.445026</td>\n",
       "      <td>0.454349</td>\n",
       "      <td>245458</td>\n",
       "      <td>8200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.524237</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.441871</td>\n",
       "      <td>262304</td>\n",
       "      <td>19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.550281</td>\n",
       "      <td>0.440905</td>\n",
       "      <td>0.449526</td>\n",
       "      <td>289922</td>\n",
       "      <td>18200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.660226</td>\n",
       "      <td>0.555258</td>\n",
       "      <td>0.437688</td>\n",
       "      <td>0.444540</td>\n",
       "      <td>203837</td>\n",
       "      <td>5100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.664388   0.550169   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.663496   0.567776   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.658145   0.535086   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.667063   0.555337   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.659631   0.548460   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.664388   0.561472   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.657848   0.524237   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.657848   0.550281   \n",
       "8                                    narrative_tfidf  0.660226   0.555258   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0  0.450645  0.459736             211325              17200  \n",
       "1  0.444587  0.454427             239686               7700  \n",
       "2  0.436441  0.443019             256564              18200  \n",
       "3  0.454075  0.464349             217451              10600  \n",
       "4  0.441998  0.450269             284224              18700  \n",
       "5  0.445026  0.454349             245458               8200  \n",
       "6  0.436364  0.441871             262304              19800  \n",
       "7  0.440905  0.449526             289922              18200  \n",
       "8  0.437688  0.444540             203837               5100  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=chi2_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, LinearSVC(), low=1000, high=21001, step=100)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7ee2901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.666468</td>\n",
       "      <td>0.556829</td>\n",
       "      <td>0.463578</td>\n",
       "      <td>0.475923</td>\n",
       "      <td>211325</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.665874</td>\n",
       "      <td>0.560497</td>\n",
       "      <td>0.457585</td>\n",
       "      <td>0.467151</td>\n",
       "      <td>239686</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.655767</td>\n",
       "      <td>0.546979</td>\n",
       "      <td>0.454261</td>\n",
       "      <td>0.467693</td>\n",
       "      <td>256564</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.656956</td>\n",
       "      <td>0.544619</td>\n",
       "      <td>0.458066</td>\n",
       "      <td>0.468521</td>\n",
       "      <td>217451</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.548785</td>\n",
       "      <td>0.459652</td>\n",
       "      <td>0.472621</td>\n",
       "      <td>284224</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.661712</td>\n",
       "      <td>0.557419</td>\n",
       "      <td>0.459358</td>\n",
       "      <td>0.471465</td>\n",
       "      <td>245458</td>\n",
       "      <td>13000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>0.542431</td>\n",
       "      <td>0.456581</td>\n",
       "      <td>0.467424</td>\n",
       "      <td>262304</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.663496</td>\n",
       "      <td>0.549416</td>\n",
       "      <td>0.458426</td>\n",
       "      <td>0.469421</td>\n",
       "      <td>289922</td>\n",
       "      <td>15000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.654875</td>\n",
       "      <td>0.532995</td>\n",
       "      <td>0.436575</td>\n",
       "      <td>0.444419</td>\n",
       "      <td>203837</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.666468   0.556829   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.665874   0.560497   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.655767   0.546979   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.656956   0.544619   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.659631   0.548785   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.661712   0.557419   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.664090   0.542431   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.663496   0.549416   \n",
       "8                                    narrative_tfidf  0.654875   0.532995   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0  0.463578  0.475923             211325               5000  \n",
       "1  0.457585  0.467151             239686              11000  \n",
       "2  0.454261  0.467693             256564               2000  \n",
       "3  0.458066  0.468521             217451               5000  \n",
       "4  0.459652  0.472621             284224               5000  \n",
       "5  0.459358  0.471465             245458              13000  \n",
       "6  0.456581  0.467424             262304               1000  \n",
       "7  0.458426  0.469421             289922              15000  \n",
       "8  0.436575  0.444419             203837              16000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=chi2_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, XGBClassifier(), low=1000, high=21001, step=1000)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94592b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>0.666468</td>\n",
       "      <td>0.556829</td>\n",
       "      <td>0.463578</td>\n",
       "      <td>0.475923</td>\n",
       "      <td>211325</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>0.668847</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.468546</td>\n",
       "      <td>0.481305</td>\n",
       "      <td>239686</td>\n",
       "      <td>18700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>0.661415</td>\n",
       "      <td>0.563185</td>\n",
       "      <td>0.461023</td>\n",
       "      <td>0.475799</td>\n",
       "      <td>256564</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>0.662010</td>\n",
       "      <td>0.548412</td>\n",
       "      <td>0.459578</td>\n",
       "      <td>0.472182</td>\n",
       "      <td>217451</td>\n",
       "      <td>1900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>0.569823</td>\n",
       "      <td>0.462847</td>\n",
       "      <td>0.476791</td>\n",
       "      <td>284224</td>\n",
       "      <td>5800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.664685</td>\n",
       "      <td>0.564261</td>\n",
       "      <td>0.462426</td>\n",
       "      <td>0.475357</td>\n",
       "      <td>245458</td>\n",
       "      <td>9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.554976</td>\n",
       "      <td>0.462818</td>\n",
       "      <td>0.476953</td>\n",
       "      <td>262304</td>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>0.667063</td>\n",
       "      <td>0.572599</td>\n",
       "      <td>0.465210</td>\n",
       "      <td>0.478508</td>\n",
       "      <td>289922</td>\n",
       "      <td>12900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>0.653389</td>\n",
       "      <td>0.526321</td>\n",
       "      <td>0.442609</td>\n",
       "      <td>0.451622</td>\n",
       "      <td>203837</td>\n",
       "      <td>5600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Features Combination  Accuracy  Precision  \\\n",
       "0                       narrative_tfidf, tfidf_title  0.666468   0.556829   \n",
       "1       narrative_tfidf, tfidf_title, tfidf_keywords  0.668847   0.582957   \n",
       "2         narrative_tfidf, tfidf_title, events_tfidf  0.661415   0.563185   \n",
       "3             narrative_tfidf, tfidf_title, entities  0.662010   0.548412   \n",
       "4  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.664090   0.569823   \n",
       "5  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.664685   0.564261   \n",
       "6  narrative_tfidf, tfidf_title, events_tfidf, en...  0.659631   0.554976   \n",
       "7  narrative_tfidf, tfidf_title, tfidf_keywords, ...  0.667063   0.572599   \n",
       "8                                    narrative_tfidf  0.653389   0.526321   \n",
       "\n",
       "     Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0  0.463578  0.475923             211325               5000  \n",
       "1  0.468546  0.481305             239686              18700  \n",
       "2  0.461023  0.475799             256564               2400  \n",
       "3  0.459578  0.472182             217451               1900  \n",
       "4  0.462847  0.476791             284224               5800  \n",
       "5  0.462426  0.475357             245458               9400  \n",
       "6  0.462818  0.476953             262304               1700  \n",
       "7  0.465210  0.478508             289922              12900  \n",
       "8  0.442609  0.451622             203837               5600  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=chi2_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, XGBClassifier(), low=1000, high=21001, step=100)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72ee1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aafb7d91",
   "metadata": {},
   "source": [
    "### Tree-based Feature Importance with xgboost  (with holdout cv)\n",
    "XGBoost, being a tree-based model, provides a feature importance ranking that can help identify the most relevant features. The feature importance scores indicate the contribution of each feature in the XGBoost model. You can use these scores to select the top-ranked features.  \n",
    "\n",
    "[SelectFromModel](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel) Setting threshold='median' means that the median value of the feature importance scores will be used as the threshold. When using 'median' as the threshold value, features with importance scores above the median will be selected, while those with scores below the median will be discarded. This approach ensures that approximately 50% of the features are retained, making it a reasonable starting point for feature selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f015f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, t, algorithms):\n",
    "    cont=0\n",
    "    # Initialize an empty list to store individual result DataFrames\n",
    "    result_dfs = []\n",
    "    # Initialize the results table\n",
    "    results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                    'F1-Score', 'Nr feature before', 'Nr features after'])\n",
    "\n",
    "    # Evaluate models for each feature combination and algorithm\n",
    "    for feature_set in feature_combinations:\n",
    "        cont += 1\n",
    "        X_train_combined = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "        X_val_combined = X_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "        # Transform the features using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "        X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "        X_val_combined_transformed = vectorizer.transform(X_val_combined)\n",
    "\n",
    "        # Nr features before\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        num_features_before = len(feature_names)\n",
    "        \n",
    "        # Tree-Based Feature Importance for XGBoost\n",
    "        xgb_model = XGBClassifier()      \n",
    "        xgb_model.fit(X_train_combined_transformed, y_train)  \n",
    "\n",
    "        # Get feature importance scores\n",
    "        feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "        # Create a feature selector based on importance scores\n",
    "        feature_selector = SelectFromModel(xgb_model, threshold=t, prefit=True)\n",
    "\n",
    "        # Select features above the threshold\n",
    "        X_train_selected = feature_selector.transform(X_train_combined_transformed)\n",
    "        X_val_selected = feature_selector.transform(X_val_combined_transformed)\n",
    "        \n",
    "        # New nr of features\n",
    "        best_num_features = X_train_selected.shape[1]\n",
    "        \n",
    "        # Train and evaluate models for each algorithm\n",
    "        for algorithm_name, algorithm in algorithms.items():\n",
    "            # Train the model\n",
    "            algorithm.fit(X_train_selected, y_train)\n",
    "\n",
    "            # Predict labels\n",
    "            y_pred = algorithm.predict(X_val_selected)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            precision = precision_score(y_val, y_pred, average='macro')\n",
    "            recall = recall_score(y_val, y_pred, average='macro')\n",
    "            f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "            # Create a DataFrame for the current combination and algorithm\n",
    "            result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                      'Algorithm': [algorithm_name],\n",
    "                                      'Accuracy': [accuracy],\n",
    "                                      'Precision': [precision],\n",
    "                                      'Recall': [recall],\n",
    "                                      'F1-Score': [f1],\n",
    "                                      'Nr feature before':[num_features_before], \n",
    "                                      'Nr features after':[best_num_features]})\n",
    "            # Append the DataFrame to the list\n",
    "            result_dfs.append(result_df)\n",
    "\n",
    "        print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "    # Concatenate all the result DataFrames into a single DataFrame\n",
    "    results = pd.concat(result_dfs, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1eaaddd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.531410</td>\n",
       "      <td>0.452127</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>211325</td>\n",
       "      <td>1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.546550</td>\n",
       "      <td>0.451500</td>\n",
       "      <td>0.462223</td>\n",
       "      <td>211325</td>\n",
       "      <td>1839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.536474</td>\n",
       "      <td>0.452782</td>\n",
       "      <td>0.460543</td>\n",
       "      <td>239686</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.664090</td>\n",
       "      <td>0.559104</td>\n",
       "      <td>0.456817</td>\n",
       "      <td>0.467326</td>\n",
       "      <td>239686</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.524460</td>\n",
       "      <td>0.451191</td>\n",
       "      <td>0.456996</td>\n",
       "      <td>256564</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.660226</td>\n",
       "      <td>0.546389</td>\n",
       "      <td>0.453691</td>\n",
       "      <td>0.463109</td>\n",
       "      <td>256564</td>\n",
       "      <td>1884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.662604</td>\n",
       "      <td>0.535939</td>\n",
       "      <td>0.453713</td>\n",
       "      <td>0.460520</td>\n",
       "      <td>217518</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.553479</td>\n",
       "      <td>0.453596</td>\n",
       "      <td>0.464237</td>\n",
       "      <td>217518</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.656956</td>\n",
       "      <td>0.533347</td>\n",
       "      <td>0.447331</td>\n",
       "      <td>0.454297</td>\n",
       "      <td>284224</td>\n",
       "      <td>1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659929</td>\n",
       "      <td>0.554190</td>\n",
       "      <td>0.454158</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>284224</td>\n",
       "      <td>1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.654578</td>\n",
       "      <td>0.521390</td>\n",
       "      <td>0.439494</td>\n",
       "      <td>0.445627</td>\n",
       "      <td>245425</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.557896</td>\n",
       "      <td>0.451632</td>\n",
       "      <td>0.462107</td>\n",
       "      <td>245425</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.652497</td>\n",
       "      <td>0.501272</td>\n",
       "      <td>0.438024</td>\n",
       "      <td>0.440315</td>\n",
       "      <td>262355</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.662307</td>\n",
       "      <td>0.533966</td>\n",
       "      <td>0.448206</td>\n",
       "      <td>0.453804</td>\n",
       "      <td>262355</td>\n",
       "      <td>1929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.542819</td>\n",
       "      <td>0.451602</td>\n",
       "      <td>0.456510</td>\n",
       "      <td>289948</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.660820</td>\n",
       "      <td>0.550596</td>\n",
       "      <td>0.456136</td>\n",
       "      <td>0.466761</td>\n",
       "      <td>289948</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.511017</td>\n",
       "      <td>0.432798</td>\n",
       "      <td>0.436433</td>\n",
       "      <td>203837</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.645957</td>\n",
       "      <td>0.518850</td>\n",
       "      <td>0.430046</td>\n",
       "      <td>0.435547</td>\n",
       "      <td>203837</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Features Combination   Algorithm  Accuracy  \\\n",
       "0                        narrative_tfidf, tfidf_title  Linear SVC  0.658740   \n",
       "1                        narrative_tfidf, tfidf_title     XGBoost  0.659334   \n",
       "2        narrative_tfidf, tfidf_title, tfidf_keywords  Linear SVC  0.659631   \n",
       "3        narrative_tfidf, tfidf_title, tfidf_keywords     XGBoost  0.664090   \n",
       "4          narrative_tfidf, tfidf_title, events_tfidf  Linear SVC  0.659334   \n",
       "5          narrative_tfidf, tfidf_title, events_tfidf     XGBoost  0.660226   \n",
       "6              narrative_tfidf, tfidf_title, entities  Linear SVC  0.662604   \n",
       "7              narrative_tfidf, tfidf_title, entities     XGBoost  0.659631   \n",
       "8   narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.656956   \n",
       "9   narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.659929   \n",
       "10  narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.654578   \n",
       "11  narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.659334   \n",
       "12  narrative_tfidf, tfidf_title, events_tfidf, en...  Linear SVC  0.652497   \n",
       "13  narrative_tfidf, tfidf_title, events_tfidf, en...     XGBoost  0.662307   \n",
       "14  narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.663793   \n",
       "15  narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.660820   \n",
       "16                                    narrative_tfidf  Linear SVC  0.650713   \n",
       "17                                    narrative_tfidf     XGBoost  0.645957   \n",
       "\n",
       "    Precision    Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0    0.531410  0.452127  0.459422             211325               1839  \n",
       "1    0.546550  0.451500  0.462223             211325               1839  \n",
       "2    0.536474  0.452782  0.460543             239686               1884  \n",
       "3    0.559104  0.456817  0.467326             239686               1884  \n",
       "4    0.524460  0.451191  0.456996             256564               1884  \n",
       "5    0.546389  0.453691  0.463109             256564               1884  \n",
       "6    0.535939  0.453713  0.460520             217518               1856  \n",
       "7    0.553479  0.453596  0.464237             217518               1856  \n",
       "8    0.533347  0.447331  0.454297             284224               1937  \n",
       "9    0.554190  0.454158  0.465730             284224               1937  \n",
       "10   0.521390  0.439494  0.445627             245425               1881  \n",
       "11   0.557896  0.451632  0.462107             245425               1881  \n",
       "12   0.501272  0.438024  0.440315             262355               1929  \n",
       "13   0.533966  0.448206  0.453804             262355               1929  \n",
       "14   0.542819  0.451602  0.456510             289948               1975  \n",
       "15   0.550596  0.456136  0.466761             289948               1975  \n",
       "16   0.511017  0.432798  0.436433             203837               1787  \n",
       "17   0.518850  0.430046  0.435547             203837               1787  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithms= {'Linear SVC': LinearSVC(), 'XGBoost': XGBClassifier()}\n",
    "t = 'mean'\n",
    "results = xgb_feature_selection(feature_combinations, X_train, X_val, y_train, y_val, t, algorithms)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4068790",
   "metadata": {},
   "source": [
    "### Tree-based Feature Importance with xgboost  (with stratified kfold cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7609acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_feature_selection_cv(feature_combinations, X_train_val, y_train_val, t, algorithms):\n",
    "    cont=0\n",
    "    # Initialize an empty list to store individual result DataFrames\n",
    "    result_dfs = []\n",
    "    # Initialize the results table\n",
    "    results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                    'F1-Score', 'Nr feature before', 'Nr features after'])\n",
    "\n",
    "    # Evaluate models for each feature combination and algorithm\n",
    "    for feature_set in feature_combinations:\n",
    "        cont += 1\n",
    "        X_train_combined = X_train_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "        # Transform the features using TF-IDF\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "        X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "\n",
    "        # Nr features before\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        num_features_before = len(feature_names)\n",
    "        \n",
    "        # Tree-Based Feature Importance for XGBoost\n",
    "        xgb_model = XGBClassifier()      \n",
    "        xgb_model.fit(X_train_combined_transformed, y_train)  \n",
    "\n",
    "        # Get feature importance scores\n",
    "        feature_importances = xgb_model.feature_importances_\n",
    "\n",
    "        # Select the top N important features (change N to your desired number)\n",
    "        N = 5\n",
    "        selected_features = feature_importance_df['Feature'].head(N).tolist()\n",
    "\n",
    "        # Extract the selected features from the original dataset\n",
    "        X_selected = X[selected_features]\n",
    "        \n",
    "        \n",
    "        # Create a feature selector based on importance scores\n",
    "        feature_selector = SelectFromModel(xgb_model, threshold=t, prefit=True)\n",
    "\n",
    "        # Select features above the threshold\n",
    "        X_train_selected = feature_selector.transform(X_train_combined_transformed)\n",
    "        \n",
    "        # New nr of features\n",
    "        best_num_features = X_train_selected.shape[1]\n",
    "        \n",
    "        # Train and evaluate models for each algorithm\n",
    "        for algorithm_name, algorithm in algorithms.items():\n",
    "            # Train the model and evaluate with cross-validation\n",
    "            cv = StratifiedKFold(n_splits=6, shuffle=True, random_state=42)\n",
    "            f1_scores = cross_val_score(algorithm, X_train_selected, y_train_val, cv=cv, scoring='f1_macro')\n",
    "            acc_scores = cross_val_score(algorithm, X_train_selected, y_train_val, cv=cv, scoring='accuracy')\n",
    "            rec_scores = cross_val_score(algorithm, X_train_selected, y_train_val, cv=cv, scoring='recall_macro')\n",
    "            prec_scores = cross_val_score(algorithm, X_train_selected, y_train_val, cv=cv, scoring='precision_macro')\n",
    "\n",
    "            # Calculate Mean Cross-validation scores\n",
    "            accuracy = acc_scores.mean()\n",
    "            precision = prec_scores.mean()\n",
    "            recall = rec_scores.mean()\n",
    "            f1 = f1_scores.mean()\n",
    "\n",
    "            # Create a DataFrame for the current combination and algorithm\n",
    "            result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                      'Algorithm': [algorithm_name],\n",
    "                                      'Accuracy': [accuracy],\n",
    "                                      'Precision': [precision],\n",
    "                                      'Recall': [recall],\n",
    "                                      'F1-Score': [f1],\n",
    "                                      'Nr feature before':[num_features_before], \n",
    "                                      'Nr features after':[best_num_features]})\n",
    "            # Append the DataFrame to the list\n",
    "            result_dfs.append(result_df)\n",
    "\n",
    "        print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "    # Concatenate all the result DataFrames into a single DataFrame\n",
    "    results = pd.concat(result_dfs, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d8c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms= {'Linear SVC': LinearSVC(), 'XGBoost': XGBClassifier()}\n",
    "t = 'mean'\n",
    "results = xgb_feature_selection_cv(feature_combinations, X_train_val, y_train_val, t, algorithms)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7f5f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "59c0bd9f",
   "metadata": {},
   "source": [
    "### L1 Regularization (LASSO) with LinearSVC  \n",
    "[L1 based feature selection sklearn](https://scikit-learn.org/stable/modules/feature_selection.html)  \n",
    "Linear models such as LinearSVC can be regularized using L1 penalty (Lasso). This induces sparsity in the coefficients, allowing you to select important features based on their non-zero coefficients.  \n",
    "[LinearSVC sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html): Prefer dual=False when n_samples > n_features. dual=False is a parameter setting that is used to specify the algorithm used for optimization. When n_features > n_samples it is generally recommended to set dual=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41951200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bb8bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested combination 1 of 9\n",
      "Tested combination 2 of 9\n",
      "Tested combination 3 of 9\n",
      "Tested combination 4 of 9\n",
      "Tested combination 5 of 9\n",
      "Tested combination 6 of 9\n",
      "Tested combination 7 of 9\n",
      "Tested combination 8 of 9\n",
      "Tested combination 9 of 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Combination</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Nr feature before</th>\n",
       "      <th>Nr features after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.656659</td>\n",
       "      <td>0.513590</td>\n",
       "      <td>0.454399</td>\n",
       "      <td>0.462152</td>\n",
       "      <td>211325</td>\n",
       "      <td>5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>narrative_tfidf, tfidf_title</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.653092</td>\n",
       "      <td>0.548742</td>\n",
       "      <td>0.446319</td>\n",
       "      <td>0.457536</td>\n",
       "      <td>211325</td>\n",
       "      <td>5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.646849</td>\n",
       "      <td>0.497881</td>\n",
       "      <td>0.438110</td>\n",
       "      <td>0.444770</td>\n",
       "      <td>239686</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.662010</td>\n",
       "      <td>0.539544</td>\n",
       "      <td>0.449993</td>\n",
       "      <td>0.457471</td>\n",
       "      <td>239686</td>\n",
       "      <td>6141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.507549</td>\n",
       "      <td>0.443724</td>\n",
       "      <td>0.451573</td>\n",
       "      <td>256564</td>\n",
       "      <td>5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.666171</td>\n",
       "      <td>0.565995</td>\n",
       "      <td>0.462610</td>\n",
       "      <td>0.474662</td>\n",
       "      <td>256564</td>\n",
       "      <td>5701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.656956</td>\n",
       "      <td>0.519443</td>\n",
       "      <td>0.456934</td>\n",
       "      <td>0.465948</td>\n",
       "      <td>217518</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>narrative_tfidf, tfidf_title, entities</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.662010</td>\n",
       "      <td>0.562623</td>\n",
       "      <td>0.455221</td>\n",
       "      <td>0.466934</td>\n",
       "      <td>217518</td>\n",
       "      <td>5765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.653389</td>\n",
       "      <td>0.505856</td>\n",
       "      <td>0.441580</td>\n",
       "      <td>0.448257</td>\n",
       "      <td>284224</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.659334</td>\n",
       "      <td>0.550635</td>\n",
       "      <td>0.456959</td>\n",
       "      <td>0.469050</td>\n",
       "      <td>284224</td>\n",
       "      <td>5894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.645957</td>\n",
       "      <td>0.501680</td>\n",
       "      <td>0.438808</td>\n",
       "      <td>0.446428</td>\n",
       "      <td>245425</td>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.663199</td>\n",
       "      <td>0.538343</td>\n",
       "      <td>0.452456</td>\n",
       "      <td>0.459633</td>\n",
       "      <td>245425</td>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.650713</td>\n",
       "      <td>0.513240</td>\n",
       "      <td>0.444724</td>\n",
       "      <td>0.453075</td>\n",
       "      <td>262355</td>\n",
       "      <td>5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>narrative_tfidf, tfidf_title, events_tfidf, en...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.660820</td>\n",
       "      <td>0.550855</td>\n",
       "      <td>0.453136</td>\n",
       "      <td>0.463195</td>\n",
       "      <td>262355</td>\n",
       "      <td>5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.507287</td>\n",
       "      <td>0.443539</td>\n",
       "      <td>0.450786</td>\n",
       "      <td>289948</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>narrative_tfidf, tfidf_title, tfidf_keywords, ...</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.658740</td>\n",
       "      <td>0.538382</td>\n",
       "      <td>0.450512</td>\n",
       "      <td>0.460704</td>\n",
       "      <td>289948</td>\n",
       "      <td>5893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.648633</td>\n",
       "      <td>0.511422</td>\n",
       "      <td>0.446613</td>\n",
       "      <td>0.455243</td>\n",
       "      <td>203837</td>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>narrative_tfidf</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.647444</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>0.437266</td>\n",
       "      <td>0.446818</td>\n",
       "      <td>203837</td>\n",
       "      <td>6066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Features Combination   Algorithm  Accuracy  \\\n",
       "0                        narrative_tfidf, tfidf_title  Linear SVC  0.656659   \n",
       "1                        narrative_tfidf, tfidf_title     XGBoost  0.653092   \n",
       "2        narrative_tfidf, tfidf_title, tfidf_keywords  Linear SVC  0.646849   \n",
       "3        narrative_tfidf, tfidf_title, tfidf_keywords     XGBoost  0.662010   \n",
       "4          narrative_tfidf, tfidf_title, events_tfidf  Linear SVC  0.650713   \n",
       "5          narrative_tfidf, tfidf_title, events_tfidf     XGBoost  0.666171   \n",
       "6              narrative_tfidf, tfidf_title, entities  Linear SVC  0.656956   \n",
       "7              narrative_tfidf, tfidf_title, entities     XGBoost  0.662010   \n",
       "8   narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.653389   \n",
       "9   narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.659334   \n",
       "10  narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.645957   \n",
       "11  narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.663199   \n",
       "12  narrative_tfidf, tfidf_title, events_tfidf, en...  Linear SVC  0.650713   \n",
       "13  narrative_tfidf, tfidf_title, events_tfidf, en...     XGBoost  0.660820   \n",
       "14  narrative_tfidf, tfidf_title, tfidf_keywords, ...  Linear SVC  0.651605   \n",
       "15  narrative_tfidf, tfidf_title, tfidf_keywords, ...     XGBoost  0.658740   \n",
       "16                                    narrative_tfidf  Linear SVC  0.648633   \n",
       "17                                    narrative_tfidf     XGBoost  0.647444   \n",
       "\n",
       "    Precision    Recall  F1-Score  Nr feature before  Nr features after  \n",
       "0    0.513590  0.454399  0.462152             211325               5835  \n",
       "1    0.548742  0.446319  0.457536             211325               5835  \n",
       "2    0.497881  0.438110  0.444770             239686               6141  \n",
       "3    0.539544  0.449993  0.457471             239686               6141  \n",
       "4    0.507549  0.443724  0.451573             256564               5701  \n",
       "5    0.565995  0.462610  0.474662             256564               5701  \n",
       "6    0.519443  0.456934  0.465948             217518               5765  \n",
       "7    0.562623  0.455221  0.466934             217518               5765  \n",
       "8    0.505856  0.441580  0.448257             284224               5894  \n",
       "9    0.550635  0.456959  0.469050             284224               5894  \n",
       "10   0.501680  0.438808  0.446428             245425               6086  \n",
       "11   0.538343  0.452456  0.459633             245425               6086  \n",
       "12   0.513240  0.444724  0.453075             262355               5660  \n",
       "13   0.550855  0.453136  0.463195             262355               5660  \n",
       "14   0.507287  0.443539  0.450786             289948               5893  \n",
       "15   0.538382  0.450512  0.460704             289948               5893  \n",
       "16   0.511422  0.446613  0.455243             203837               6066  \n",
       "17   0.531293  0.437266  0.446818             203837               6066  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the results table\n",
    "cont=0\n",
    "\n",
    "# Initialize an empty list to store individual result DataFrames\n",
    "result_dfs = []\n",
    "# Initialize the results table\n",
    "results = pd.DataFrame(columns=['Features Combination', 'Accuracy', 'Precision', 'Recall', \n",
    "                                'F1-Score', 'Nr feature before', 'Nr features after'])\n",
    "\n",
    "# Evaluate models for each feature combination and algorithm\n",
    "for feature_set in feature_combinations:\n",
    "    cont += 1\n",
    "    X_train_combined = X_train[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "    X_val_combined = X_val[feature_set].apply(lambda x: ' '.join(x.fillna('').astype(str)), axis=1)\n",
    "\n",
    "    # Transform the features using TF-IDF\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.95, min_df=2)\n",
    "    X_train_combined_transformed = vectorizer.fit_transform(X_train_combined)\n",
    "    X_val_combined_transformed = vectorizer.transform(X_val_combined)\n",
    "\n",
    "    # Nr features before\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    num_features_before = len(feature_names)\n",
    "    \n",
    "    # L1 Regularization (Lasso) for Linear SVC\n",
    "    svc_model = LinearSVC(penalty='l1', dual=False)  \n",
    "    svc_model.fit(X_train_combined_transformed, y_train)                 \n",
    "\n",
    "    # Select features based on non-zero coefficients\n",
    "    feature_selector = SelectFromModel(svc_model)\n",
    "    feature_selector.fit(X_train_combined_transformed, y_train)\n",
    "    X_train_selected = feature_selector.transform(X_train_combined_transformed)\n",
    "    X_val_selected = feature_selector.transform(X_val_combined_transformed)\n",
    "\n",
    "    # New number of features\n",
    "    best_num_features= X_train_selected.shape[1]\n",
    "\n",
    "    # Train and evaluate models for each algorithm\n",
    "    algorithms= {'Linear SVC': LinearSVC(), 'XGBoost': XGBClassifier()}\n",
    "    for algorithm_name, algorithm in algorithms.items():\n",
    "        # Train the model\n",
    "        algorithm.fit(X_train_selected, y_train)\n",
    "\n",
    "        # Predict labels\n",
    "        y_pred = algorithm.predict(X_val_selected)\n",
    "\n",
    "        # Calculate performance metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision = precision_score(y_val, y_pred, average='macro')\n",
    "        recall = recall_score(y_val, y_pred, average='macro')\n",
    "        f1 = f1_score(y_val, y_pred, average='macro')\n",
    "\n",
    "        # Create a DataFrame for the current combination and algorithm\n",
    "        result_df = pd.DataFrame({'Features Combination': [', '.join(feature_set)],\n",
    "                                      'Algorithm': [algorithm_name],\n",
    "                                      'Accuracy': [accuracy],\n",
    "                                      'Precision': [precision],\n",
    "                                      'Recall': [recall],\n",
    "                                      'F1-Score': [f1],\n",
    "                                      'Nr feature before':[num_features_before], \n",
    "                                      'Nr features after':[best_num_features]})\n",
    "        # Append the DataFrame to the list\n",
    "        result_dfs.append(result_df)\n",
    "        \n",
    "    print(\"Tested combination {} of {}\".format(cont, len(feature_combinations)))\n",
    "\n",
    "# Concatenate all the result DataFrames into a single DataFrame\n",
    "results = pd.concat(result_dfs, ignore_index=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "508ea1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9be2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d6f915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92141c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b59d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eac1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9eabfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d1be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
